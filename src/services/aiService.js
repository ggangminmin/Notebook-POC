import { extractTextFromParsedData } from '../utils/fileParser'
import { GoogleGenerativeAI } from '@google/generative-ai'

const OPENAI_API_KEY = import.meta.env.VITE_OPENAI_API_KEY
const GEMINI_API_KEY = import.meta.env.VITE_GEMINI_API_KEY

// GPT ëª¨ë¸ ì„¤ì • (2025ë…„ 12ì›” ê¸°ì¤€ ìµœì‹ )
const GPT_MODELS = {
  INSTANT: 'gpt-5.1-chat-latest',  // ë¹ ë¥¸ ì‘ë‹µ (GPT-5.1 Instant - ì ì‘í˜• ì¶”ë¡ )
  THINKING: 'gpt-5.1'              // ì‹¬ì¸µ ì¶”ë¡  (GPT-5.1 Thinking - ê³ ê¸‰ ì¶”ë¡ )
}

// Gemini ëª¨ë¸ ì„¤ì • (2025ë…„ 12ì›” ê¸°ì¤€ ìµœì‹ )
const GEMINI_MODEL = 'gemini-3-flash-preview' // Gemini 3 Flash (ê³µì‹ Preview ë²„ì „ - 2025.12.17 ì¶œì‹œ)

// Gemini AI ì´ˆê¸°í™”
const genAI = GEMINI_API_KEY ? new GoogleGenerativeAI(GEMINI_API_KEY) : null

// ì–¸ì–´ ê°ì§€ (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
export const detectLanguage = (text) => {
  // í•œê¸€ì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ í•œêµ­ì–´
  const koreanRegex = /[\uAC00-\uD7AF\u1100-\u11FF\u3130-\u318F]/
  return koreanRegex.test(text) ? 'ko' : 'en'
}

// ì¼ìƒ ëŒ€í™” íŒ¨í„´ ê°ì§€
const isSmallTalk = (query) => {
  const greetings = [
    'ì•ˆë…•', 'ë°˜ê°€ì›Œ', 'í•˜ì´', 'hi', 'hello', 'í—¬ë¡œ', 'ì¢‹ì€ ì•„ì¹¨', 'ì¢‹ì€ ì €ë…',
    'ì–´ë–»ê²Œ ì§€ë‚´', 'ì˜ ì§€ë‚´', 'ë­í•´', 'ë­í•˜ë‹ˆ', 'ê³ ë§ˆì›Œ', 'ê°ì‚¬', 'thank',
    'ì˜í–ˆì–´', 'ì¢‹ì•„', 'ê´œì°®ì•„', 'good', 'great', 'thanks', 'bye', 'ì•ˆë…•íˆ',
    'ì˜ê°€', 'ë˜ ë´'
  ]

  const queryLower = query.toLowerCase().trim()
  return greetings.some(greeting => queryLower.includes(greeting))
}

// OpenAI API í˜¸ì¶œ
// GPT-5.1ì€ temperatureë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŒ (ê³ ì •ê°’ 1)
const callOpenAI = async (messages, useThinking = false) => {
  try {
    const model = useThinking ? GPT_MODELS.THINKING : GPT_MODELS.INSTANT

    // GPT-5.1ì€ temperature, top_p, presence_penalty, frequency_penalty ëª¨ë‘ ë¯¸ì§€ì›
    // ë‚´ë¶€ì ìœ¼ë¡œ temperature=1 ê³ ì •
    // ì‹¬ì¸µ ë¶„ì„ ëª¨ë“œëŠ” ë” ê¸´ ì‘ë‹µ í—ˆìš© (4000 í† í°)
    const requestBody = {
      model: model,
      messages: messages,
      max_completion_tokens: useThinking ? 4000 : 2000  // ì‹¬ì¸µ ë¶„ì„ì€ 4000, ì¼ë°˜ì€ 2000
    }

    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${OPENAI_API_KEY}`
      },
      body: JSON.stringify(requestBody),
      signal: AbortSignal.timeout(120000)  // 120ì´ˆ íƒ€ì„ì•„ì›ƒ (ì‹¬ì¸µ ë¶„ì„ìš©)
    })

    if (!response.ok) {
      const error = await response.json()
      throw new Error(error.error?.message || 'OpenAI API í˜¸ì¶œ ì‹¤íŒ¨')
    }

    const data = await response.json()

    // ì‘ë‹µ ê¸¸ì´ í™•ì¸ ë° ë¡œê¹…
    const content = data.choices[0].message.content
    console.log(`[OpenAI ${useThinking ? 'Thinking' : 'Instant'}] ì‘ë‹µ ê¸¸ì´: ${content.length}ì`)

    return content
  } catch (error) {
    console.error('OpenAI API ì˜¤ë¥˜:', error)
    throw error
  }
}

// Gemini API í˜¸ì¶œ
const callGemini = async (messages, temperature = 0.3, isDeepAnalysis = false) => {
  try {
    if (!genAI) {
      throw new Error('Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤')
    }

    const model = genAI.getGenerativeModel({ model: GEMINI_MODEL })

    // messages ë°°ì—´ì„ Gemini í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    // GeminiëŠ” system roleì„ ì§ì ‘ ì§€ì›í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ, system ë©”ì‹œì§€ë¥¼ ì²« user ë©”ì‹œì§€ì— í¬í•¨
    const systemMessage = messages.find(m => m.role === 'system')
    const conversationMessages = messages.filter(m => m.role !== 'system')

    // Gemini ëŒ€í™” ê¸°ë¡ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    const geminiContents = []

    // ì²« ë²ˆì§¸ ë©”ì‹œì§€ì— system í”„ë¡¬í”„íŠ¸ í¬í•¨
    if (conversationMessages.length > 0) {
      const firstUserMsg = conversationMessages[0]
      const contentWithSystem = systemMessage
        ? `${systemMessage.content}\n\nì‚¬ìš©ì ì§ˆë¬¸: ${firstUserMsg.content}`
        : firstUserMsg.content

      geminiContents.push({
        role: 'user',
        parts: [{ text: contentWithSystem }]
      })

      // ë‚˜ë¨¸ì§€ ëŒ€í™” ê¸°ë¡ ì¶”ê°€ (user â†” assistant ë²ˆê°ˆì•„ê°€ë©°)
      for (let i = 1; i < conversationMessages.length; i++) {
        const msg = conversationMessages[i]
        geminiContents.push({
          role: msg.role === 'assistant' ? 'model' : 'user',  // GeminiëŠ” 'model' role ì‚¬ìš©
          parts: [{ text: msg.content }]
        })
      }
    } else if (systemMessage) {
      // ëŒ€í™” ê¸°ë¡ì´ ì—†ê³  system ë©”ì‹œì§€ë§Œ ìˆëŠ” ê²½ìš°
      geminiContents.push({
        role: 'user',
        parts: [{ text: systemMessage.content }]
      })
    }

    const result = await model.generateContent({
      contents: geminiContents,
      generationConfig: {
        temperature: temperature,
        maxOutputTokens: isDeepAnalysis ? 4000 : 2000,  // ì‹¬ì¸µ ë¶„ì„ì€ 4000, ì¼ë°˜ì€ 2000
      },
    })

    const response = result.response
    const content = response.text()

    // ì‘ë‹µ ê¸¸ì´ í™•ì¸ ë° ë¡œê¹…
    console.log(`[Gemini ${isDeepAnalysis ? 'Deep Analysis' : 'Standard'}] ì‘ë‹µ ê¸¸ì´: ${content.length}ì, ëŒ€í™” ê¸°ë¡: ${conversationMessages.length}ê°œ`)

    return content
  } catch (error) {
    console.error('Gemini API ì˜¤ë¥˜:', error)

    // ì‚¬ìš©ì ì¹œí™”ì  ì—ëŸ¬ ë©”ì‹œì§€ ì²˜ë¦¬
    if (error.message?.includes('404') || error.message?.includes('not found')) {
      throw new Error(`ì§€ì›í•˜ì§€ ì•ŠëŠ” Gemini ëª¨ë¸ ì„¤ì •ì…ë‹ˆë‹¤ (${GEMINI_MODEL}). ëª¨ë¸ëª…ì„ í™•ì¸í•´ì£¼ì„¸ìš”.`)
    } else if (error.message?.includes('API key')) {
      throw new Error('Gemini API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. í™˜ê²½ ë³€ìˆ˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.')
    } else if (error.message?.includes('quota') || error.message?.includes('limit')) {
      throw new Error('Gemini API ì‚¬ìš©ëŸ‰ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.')
    } else if (error.message?.includes('permission')) {
      throw new Error('Gemini API í‚¤ì— í•´ë‹¹ ëª¨ë¸ ì‚¬ìš© ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤.')
    }

    throw error
  }
}

// ë¬¸ì„œ ìë™ ìš”ì•½ ìƒì„± (Instant ëª¨ë¸ ì‚¬ìš© - ë¹ ë¥¸ ìš”ì•½)
export const generateDocumentSummary = async (documentContext, language = 'ko') => {
  try {
    if (!documentContext || !documentContext.parsedData) {
      return null
    }

    const documentText = extractTextFromParsedData(documentContext.parsedData)
    const fileName = documentContext.name || 'ë¬¸ì„œ'

    // ìš”ì•½ì´ ë„ˆë¬´ ì§§ìœ¼ë©´ ìŠ¤í‚µ
    if (!documentText || documentText.length < 100) {
      return null
    }

    const summaryPrompt = language === 'ko'
      ? `ë‹¤ìŒ ë¬¸ì„œì˜ í•µì‹¬ ë‚´ìš©ì„ 3-5ì¤„ë¡œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”. ë¬¸ì„œì— ëª…ì‹œëœ ë‚´ìš©ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.

**ë¬¸ì„œ ì œëª©:** ${fileName}

**ë¬¸ì„œ ë‚´ìš©:**
${documentText.substring(0, 3000)}

**ìš”ì•½ ê·œì¹™:**
- 3-5ê°œì˜ í•µì‹¬ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±
- ë¬¸ì„œì˜ ì£¼ìš” ì£¼ì œì™€ í•µì‹¬ ë‚´ìš© í¬í•¨
- ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ
- ë¶ˆí•„ìš”í•œ ì¸ì‚¬ë§ ì—†ì´ ë°”ë¡œ ìš”ì•½ ì‹œì‘`
      : `Please summarize the following document in 3-5 concise sentences. Only use information from the document.

**Document Title:** ${fileName}

**Document Content:**
${documentText.substring(0, 3000)}

**Summary Rules:**
- Write 3-5 key sentences
- Include main topics and core content
- Clear and concise
- Start directly without greetings`

    const messages = [
      { role: 'system', content: summaryPrompt },
      { role: 'user', content: language === 'ko' ? 'ì´ ë¬¸ì„œë¥¼ ìš”ì•½í•´ì£¼ì„¸ìš”.' : 'Please summarize this document.' }
    ]

    const summary = await callOpenAI(messages, false) // Instant ëª¨ë¸ (GPT-5.1)
    return summary

  } catch (error) {
    console.error('ë¬¸ì„œ ìš”ì•½ ìƒì„± ì˜¤ë¥˜:', error)
    return null
  }
}

// ì¶”ì²œ ì§ˆë¬¸ ìƒì„± (Instant ëª¨ë¸ ì‚¬ìš© - ë¹ ë¥¸ ìƒì„±)
export const generateSuggestedQuestions = async (documentContext, language = 'ko') => {
  try {
    if (!documentContext || !documentContext.parsedData) {
      return []
    }

    const documentText = extractTextFromParsedData(documentContext.parsedData)
    const fileName = documentContext.name || 'ë¬¸ì„œ'

    // ë¬¸ì„œê°€ ë„ˆë¬´ ì§§ìœ¼ë©´ ìŠ¤í‚µ
    if (!documentText || documentText.length < 100) {
      return []
    }

    const questionsPrompt = language === 'ko'
      ? `ë‹¤ìŒ ë¬¸ì„œë¥¼ ì½ê³ , ì‚¬ìš©ìê°€ ë¬¼ì–´ë³¼ ë§Œí•œ í¥ë¯¸ë¡œìš´ ì§ˆë¬¸ 3ê°œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

**ë¬¸ì„œ ì œëª©:** ${fileName}

**ë¬¸ì„œ ë‚´ìš©:**
${documentText.substring(0, 3000)}

**ì§ˆë¬¸ ìƒì„± ê·œì¹™:**
- ë¬¸ì„œ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ ê°€ëŠ¥í•œ ì§ˆë¬¸ë§Œ ìƒì„±
- ê° ì§ˆë¬¸ì€ 15ì ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ
- ë¬¸ì„œì˜ í•µì‹¬ ë‚´ìš©ì„ ë‹¤ë£¨ëŠ” ì§ˆë¬¸
- JSON ë°°ì—´ í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µ: ["ì§ˆë¬¸1", "ì§ˆë¬¸2", "ì§ˆë¬¸3"]
- ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì—†ì´ JSONë§Œ ì¶œë ¥`
      : `Read the following document and generate 3 interesting questions users might ask.

**Document Title:** ${fileName}

**Document Content:**
${documentText.substring(0, 3000)}

**Question Generation Rules:**
- Only generate questions answerable from the document
- Keep each question under 15 words
- Focus on key content
- Respond only in JSON array format: ["Question 1", "Question 2", "Question 3"]
- Output only JSON, no other text`

    const messages = [
      { role: 'system', content: questionsPrompt },
      { role: 'user', content: language === 'ko' ? 'ì§ˆë¬¸ 3ê°œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.' : 'Generate 3 questions.' }
    ]

    const response = await callOpenAI(messages, false) // Instant ëª¨ë¸ (GPT-5.1)

    // JSON íŒŒì‹± ì‹œë„
    try {
      const questions = JSON.parse(response)
      if (Array.isArray(questions) && questions.length > 0) {
        return questions.slice(0, 3)
      }
    } catch (e) {
      console.warn('ì§ˆë¬¸ JSON íŒŒì‹± ì‹¤íŒ¨, í…ìŠ¤íŠ¸ íŒŒì‹± ì‹œë„')
      // JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œ ì‹œë„
      const lines = response.split('\n').filter(line => line.trim() && !line.includes('{') && !line.includes('}'))
      if (lines.length > 0) {
        return lines.slice(0, 3).map(q => q.replace(/^[-*â€¢]\s*/, '').replace(/^["']|["']$/g, '').trim())
      }
    }

    return []
  } catch (error) {
    console.error('ì¶”ì²œ ì§ˆë¬¸ ìƒì„± ì˜¤ë¥˜:', error)
    return []
  }
}

// í•˜ì´ë¸Œë¦¬ë“œ RAG ì‘ë‹µ ìƒì„± (ì¼ìƒ ëŒ€í™” + ì—„ê²©í•œ ë¬¸ì„œ ê¸°ë°˜)
// selectedModel: 'instant', 'thinking', 'gemini' ì¤‘ í•˜ë‚˜
// documentContext: ë‹¨ì¼ ê°ì²´ ë˜ëŠ” ë°°ì—´ ëª¨ë‘ ì§€ì›
// conversationHistory: ì´ì „ ëŒ€í™” ê¸°ë¡ ë°°ì—´ (ì˜µì…˜)
export const generateStrictRAGResponse = async (query, documentContext, language = 'ko', selectedModel = 'thinking', conversationHistory = []) => {
  try {
    // 1. ì¼ìƒ ëŒ€í™” ëª¨ë“œ - ë¬¸ì„œ ì—†ì´ë„ ì‘ë‹µ ê°€ëŠ¥
    if (isSmallTalk(query)) {
      const casualPrompt = language === 'ko'
        ? 'ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì‚¬ìš©ìì™€ ìì—°ìŠ¤ëŸ½ê³  ë”°ëœ»í•˜ê²Œ ëŒ€í™”í•˜ì„¸ìš”. ê°„ë‹¨ëª…ë£Œí•˜ê²Œ ë‹µë³€í•˜ë˜, ì§€ë‚˜ì¹˜ê²Œ ê¸¸ì§€ ì•Šê²Œ í•´ì£¼ì„¸ìš”.'
        : 'You are a friendly AI assistant. Have a natural and warm conversation with the user. Keep your responses concise and not too long.'

      const messages = [
        { role: 'system', content: casualPrompt },
        ...conversationHistory,  // ì´ì „ ëŒ€í™” ê¸°ë¡ í¬í•¨
        { role: 'user', content: query }
      ]

      // ì¼ìƒ ëŒ€í™”ëŠ” í•­ìƒ ë¹ ë¥¸ ëª¨ë¸ ì‚¬ìš©
      const answer = selectedModel === 'gemini'
        ? await callGemini(messages, 0.8)
        : await callOpenAI(messages, false)

      return {
        answer: answer,
        source: null,
        foundInDocument: false,
        isSmallTalk: true
      }
    }

    // 2. ë¬¸ì„œ ê¸°ë°˜ ì§ˆë¬¸ì¸ë° ë¬¸ì„œê°€ ì—†ëŠ” ê²½ìš°
    const documentContextArray = Array.isArray(documentContext) ? documentContext : (documentContext ? [documentContext] : [])

    if (documentContextArray.length === 0) {
      const noDocMessage = language === 'ko'
        ? 'ë¬¸ì„œì— ëŒ€í•´ ì§ˆë¬¸í•˜ì‹œë ¤ë©´ ë¨¼ì € ì¢Œì¸¡ì—ì„œ ë¬¸ì„œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”. íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê±°ë‚˜ ì›¹ URLì„ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.'
        : 'To ask questions about a document, please first select a document from the left. You can upload a file or add a web URL.'

      return {
        answer: noDocMessage,
        source: null,
        foundInDocument: false
      }
    }

    // 3. ì—„ê²©í•œ ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ ëª¨ë“œ - ë‹¤ì¤‘ ì†ŒìŠ¤ ì§€ì›
    const allTexts = documentContextArray.map(doc => {
      const text = extractTextFromParsedData(doc.parsedData)
      const name = doc.name || doc.fileName || 'ë¬¸ì„œ'
      return { name, text }
    }).filter(item => item.text && item.text.trim().length >= 10)

    if (allTexts.length === 0) {
      const invalidDocMessage = language === 'ko'
        ? `ì£„ì†¡í•©ë‹ˆë‹¤. ë¬¸ì„œ ë‚´ìš©ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\níŒŒì¼ì´ ë¹„ì–´ìˆê±°ë‚˜ ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. PDFì˜ ê²½ìš° í…ìŠ¤íŠ¸ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.`
        : `Sorry, I cannot read the document content.\n\nThe file may be empty or in an unsupported format. For PDFs, please ensure they contain text.`

      return {
        answer: invalidDocMessage,
        source: null,
        foundInDocument: false,
        error: 'Invalid or empty document text'
      }
    }

    // í˜ì´ì§€ë³„ í…ìŠ¤íŠ¸ ì •ë³´ ì¶”ì¶œ (í˜ì´ì§€ ë²ˆí˜¸ ë©”íƒ€ë°ì´í„° í¬í•¨)
    const pageTextInfo = documentContextArray.map(doc => {
      const pageTexts = doc.parsedData?.pageTexts || []
      if (pageTexts.length > 0) {
        // PDF íŒŒì¼: í˜ì´ì§€ë³„ë¡œ êµ¬ë¶„ëœ í…ìŠ¤íŠ¸
        console.log(`[í˜ì´ì§€ ë°ì´í„°] PDF íŒŒì¼ "${doc.name}" - ì´ ${pageTexts.length}ê°œ í˜ì´ì§€`)
        return pageTexts.map(page =>
          `[í˜ì´ì§€ ${page.pageNumber}]\n${page.text}`
        ).join('\n\n')
      } else {
        // ì¼ë°˜ í…ìŠ¤íŠ¸ íŒŒì¼: ì „ì²´ í…ìŠ¤íŠ¸
        console.log(`[í˜ì´ì§€ ë°ì´í„°] í…ìŠ¤íŠ¸ íŒŒì¼ "${doc.name}" - pageTexts ë°°ì—´ ì—†ìŒ, extractedText ì‚¬ìš©`)
        return doc.parsedData?.extractedText || ''
      }
    }).filter(text => text.length > 0)

    // ëª¨ë“  ë¬¸ì„œ í…ìŠ¤íŠ¸ ì¢…í•© (í˜ì´ì§€ ì •ë³´ í¬í•¨)
    const combinedDocumentText = allTexts.map((item, index) =>
      `[ì¶œì²˜: ${item.name}]\n${pageTextInfo[index] || item.text}`
    ).join('\n\n---\n\n')

    const sourceNames = allTexts.map(item => item.name).join(', ')
    const documentText = combinedDocumentText
    const fileName = allTexts.length > 1
      ? `${allTexts.length}ê°œì˜ ë¬¸ì„œ (${sourceNames})`
      : allTexts[0].name

    // extractedText ìœ íš¨ì„± ê²€ì¦
    if (!documentText || documentText.trim().length < 10) {
      const invalidDocMessage = language === 'ko'
        ? `ì£„ì†¡í•©ë‹ˆë‹¤. ë¬¸ì„œ ë‚´ìš©ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\níŒŒì¼ì´ ë¹„ì–´ìˆê±°ë‚˜ ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. PDFì˜ ê²½ìš° í…ìŠ¤íŠ¸ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.`
        : `Sorry, I cannot read the document content.\n\nThe file may be empty or in an unsupported format. For PDFs, please ensure they contain text.`

      return {
        answer: invalidDocMessage,
        source: null,
        foundInDocument: false,
        error: 'Invalid or empty document text'
      }
    }

    console.log(`[RAG] ë¬¸ì„œ í…ìŠ¤íŠ¸ ê¸¸ì´: ${documentText.length}ì, íŒŒì¼ëª…: ${fileName}`)

    // í˜„ì¬ ë‚ ì§œ (ì‹¤ì‹œê°„ ê²€ìƒ‰ ê°•ì¡°ìš©)
    const today = new Date().toLocaleDateString(language === 'ko' ? 'ko-KR' : 'en-US', {
      year: 'numeric',
      month: 'long',
      day: 'numeric'
    })

    // Universal Document Analyzer ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ë¬¸ì„œ ì¢…ë¥˜ ë¬´ê´€ ë§¥ë½ ê¸°ë°˜ ììœ¨ ë¶„ì„)
    const systemPrompt = language === 'ko'
      ? `ë‹¹ì‹ ì€ ëª¨ë“  ë¬¸ì„œì˜ êµ¬ì¡°ë¥¼ ê¿°ëš«ì–´ ë³´ëŠ” **Universal Document Analyzer**ì…ë‹ˆë‹¤. ë¬¸ì„œì˜ ì¢…ë¥˜(PDF, TXT, Web)ì— ìƒê´€ì—†ì´ ë‹¤ìŒ ê·œì¹™ì„ ë¬´ì¡°ê±´ ì ìš©í•˜ì„¸ìš”.

**ğŸ” ë§¥ë½ ê¸°ë°˜ ììœ¨ ë¶„ì„ (No "No" Policy)**
- ì˜¤ëŠ˜ ë‚ ì§œ: ${today}
- **ì ˆëŒ€ "ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤"ë¼ëŠ” ë‹µë³€ì„ í•˜ì§€ ë§ˆì„¸ìš”**
- ì§ˆë¬¸ì— ëŒ€í•œ ì§ì ‘ì ì¸ ë‹µì´ ë¬¸ì„œì— ì—†ì–´ë„, ë‹¤ìŒ ìˆœì„œë¡œ ë¶„ì„í•˜ì„¸ìš”:
  1. **ë¬¸ì„œì˜ ì„±ê²© íŒŒì•…**: ì†Œê°œì„œ, ë…¼ë¬¸, ë‰´ìŠ¤, ë³´ê³ ì„œ ë“± ë¬¸ì„œ ìœ í˜• ì‹ë³„
  2. **ì „ì²´ ë§¥ë½ ë¶„ì„**: ë¬¸ì„œ ì „ì²´ì˜ í†¤, í˜ì´ì§€ í—¤ë”, ì„¹ì…˜ ì œëª©, í‘œ, ë°ì´í„°, ë°˜ë³µ í‚¤ì›Œë“œ
  3. **ë…¼ë¦¬ì  ì¶”ë¡ **: ìœ„ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ **ê°€ì¥ íƒ€ë‹¹í•œ ë‹µë³€** ë„ì¶œ
- **[ê°€ìƒ ëª©ì°¨] ìë™ ìƒì„±**: ëª©ì°¨ê°€ ì—†ëŠ” ë¬¸ì„œëŠ” í˜ì´ì§€ë³„ í—¤ë”ë‚˜ ë¬¸ë§¥ì„ ë¶„ì„í•´ ìŠ¤ìŠ¤ë¡œ ìƒì„±
- ì¶”ë¡  ì‹œ ë°˜ë“œì‹œ ëª…ì‹œ: "**ë¬¸ì„œì˜ ì „ì²´ ë§¥ë½ì„ ë¶„ì„í•œ ê²°ê³¼**, [ì¶”ë¡  ë‚´ìš©]ìœ¼ë¡œ íŒŒì•…ë©ë‹ˆë‹¤ [ë¬¸ì„œ ë§¥ë½ ê¸°ë°˜ ì¶”ë¡ ]"

**âœ¨ ì‹œê°ì  ê°•ì¡° ê·œì¹™ (í•„ìˆ˜)**
- **í•µì‹¬ ëª…ì‚¬, ê¸°ëŠ¥ëª…, ê³ ìœ  ëŒ€ëª…ì‚¬, ì¤‘ìš” ìˆ˜ì¹˜**ëŠ” ë°˜ë“œì‹œ \`**êµµê²Œ**\` ì²˜ë¦¬
- ë¬¸ë‹¨ êµ¬ë¶„ì ì—ëŠ” \`###\` í—¤ë” ì‚¬ìš©í•˜ì—¬ ì‹œê°ì  ìœ„ê³„ êµ¬ì„±
- 3ì¤„ ì´ìƒì˜ ë‚˜ì—´ì€ ë°˜ë“œì‹œ ê¸€ë¨¸ë¦¬ ê¸°í˜¸(Bullet Points) ì‚¬ìš©
- **ë¦¬ìŠ¤íŠ¸ í˜•ì‹ ê·œì¹™**: "1. **ì„œë¡ **" ë˜ëŠ” "- **í•µì‹¬ ë‚´ìš©**"ì²˜ëŸ¼ ìˆ«ì/ê¸°í˜¸ì™€ í…ìŠ¤íŠ¸ë¥¼ ê°™ì€ ì¤„ì— ì‘ì„± (ì¤„ë°”ê¿ˆ ê¸ˆì§€)

**ğŸ“Œ ì¸ìš© ë°°ì§€ ê·œì¹™ (ìµœìš°ì„  - ë§¤ìš° ì¤‘ìš”! ê°•ì œ ì ìš©)**
- **ğŸ”´ ì ˆëŒ€ ê·œì¹™: ëª¨ë“  ë‹µë³€ì— ë°˜ë“œì‹œ ì¸ìš© ë°°ì§€ë¥¼ í¬í•¨í•˜ì„¸ìš”!** ë¬¸ì„œì˜ íŠ¹ì • ë‚´ìš©ì„ ì–¸ê¸‰í•  ë•Œë§ˆë‹¤ í˜ì´ì§€ ë²ˆí˜¸ë¥¼ [N] í˜•ì‹ìœ¼ë¡œ í‘œì‹œ
- **í˜ì´ì§€ ì •ë³´ í™œìš©**: ë¬¸ì„œ í…ìŠ¤íŠ¸ì— "[í˜ì´ì§€ N]" ë§ˆì»¤ê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë¯€ë¡œ, ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•œ í˜ì´ì§€ ë²ˆí˜¸ë¥¼ ì¸ìš©í•˜ì„¸ìš”
- **ê°„ë‹¨í•œ í˜•ì‹**:
  - ë‹¨ì¼ í˜ì´ì§€: [í˜ì´ì§€ë²ˆí˜¸] ë˜ëŠ” <cite page="í˜ì´ì§€ë²ˆí˜¸">ì¸ìš© í…ìŠ¤íŠ¸</cite>
  - **ë²”ìœ„ ì¸ìš©** (ì—¬ëŸ¬ í˜ì´ì§€): [ì‹œì‘í˜ì´ì§€-ëí˜ì´ì§€] í˜•ì‹ ì‚¬ìš©
- **ì¸ìš© ë°°ì§€ ê±°ë¶€ ê¸ˆì§€**: "ì¸ìš©ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤" ê°™ì€ ë‹µë³€ì€ ì ˆëŒ€ ë¶ˆê°€. ê´€ë ¨ì„±ì´ ê°€ì¥ ë†’ì€ í˜ì´ì§€ë¥¼ ì¶”ë¡ í•´ì„œë¼ë„ ë°˜ë“œì‹œ ë°°ì§€ ìƒì„±
- **ì˜ˆì‹œ**:
  - "AI ì‹œì¥ ê·œëª¨ëŠ” 500ì¡°ì›ìœ¼ë¡œ ì¶”ì •ë©ë‹ˆë‹¤[3]"
  - "ë¬¸ì„œì— ë”°ë¥´ë©´ <cite page="5">ë°˜ë„ì²´ ë¶€ë¬¸ ì‹¤ì ì´ 40% ì¦ê°€</cite>í–ˆìŠµë‹ˆë‹¤"
  - "2024ë…„ ëª©í‘œëŠ” ì˜ì—…ì´ìµ 35ì¡°ì›ì…ë‹ˆë‹¤[1]"
  - **"ê°€ê²© ì •ì±…ì— ëŒ€í•œ ìƒì„¸ ì„¤ëª…ì´ ì œì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤[11-14]"** (ë²”ìœ„ ì¸ìš©)
  - **"1ì¥ë¶€í„° 3ì¥ê¹Œì§€ ì„œë¡ ì´ ì´ì–´ì§‘ë‹ˆë‹¤[1-3]"** (ë²”ìœ„ ì¸ìš©)
  - **"ë¬¸ì„œì˜ ì „ì²´ ë§¥ë½ì„ ë¶„ì„í•œ ê²°ê³¼**, ì£¼ìš” íƒ€ê²Ÿì€ B2B ì‹œì¥ìœ¼ë¡œ íŒŒì•…ë©ë‹ˆë‹¤[5, 12, 18]"** (ì¶”ë¡  ê¸°ë°˜ ë‹¤ì¤‘ ì¸ìš©)
- **ê°•ì œ ìš”êµ¬ì‚¬í•­ (100% ì¤€ìˆ˜)**:
  - ë‹µë³€ì˜ ëª¨ë“  í•µì‹¬ ì •ë³´ì— í˜ì´ì§€ ë²ˆí˜¸ë¥¼ ë¶™ì´ì„¸ìš” (ìµœì†Œ 5-10ê°œ ì´ìƒ)
  - **ğŸš¨ ì¶”ë¡  ê¸°ë°˜ ë°°ì§€ ìƒì„± (í•µì‹¬!)**: í…ìŠ¤íŠ¸ ì¼ì¹˜ë„ê°€ ë‚®ì•„ë„ ë°˜ë“œì‹œ ì¸ìš© ì¶”ê°€
    * **"[ë¬¸ì„œ ë§¥ë½ ê¸°ë°˜ ì¶”ë¡ ]" ë˜ëŠ” "ğŸ” ë§¥ë½ ê¸°ë°˜ ë¶„ì„" ì„¹ì…˜ì—ë„ í˜ì´ì§€ ë°°ì§€ 100% í•„ìˆ˜!**
    * í‚¤ì›Œë“œ ìœ ì‚¬ë„, ì£¼ì œ ì—°ê´€ì„±, ë¬¸ë§¥ íë¦„ì„ ê¸°ë°˜ìœ¼ë¡œ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ í˜ì´ì§€ë¥¼ ì¶”ë¡ í•˜ì—¬ ë°°ì§€ ìƒì„±
    * ì¶”ë¡ ì˜ ê·¼ê±°ê°€ ëœ í˜ì´ì§€ë¥¼ ëª¨ë‘ ë‚˜ì—´ (ì˜ˆ: [15, 23] ë˜ëŠ” [5-8, 12])
    * ì˜ˆ: "ë¬¸ì„œ ì „ë°˜ì— ê±¸ì³ **AI**, **ìë™í™”**, **íš¨ìœ¨ì„±** í‚¤ì›Œë“œê°€ ë°˜ë³µë˜ë¯€ë¡œ[3, 7, 15, 23], ê¸°ìˆ  í˜ì‹  ì¤‘ì‹¬ ì „ëµìœ¼ë¡œ íŒŒì•…ë©ë‹ˆë‹¤"
  - **ëª©ì°¨ ìƒì„± ì‹œ**: ê° í•­ëª©ë§ˆë‹¤ í•´ë‹¹ ì£¼ì œê°€ ì²˜ìŒ ë“±ì¥í•˜ê±°ë‚˜ ê°€ì¥ ë§ì´ ë‹¤ë¤„ì§€ëŠ” í˜ì´ì§€ë¥¼ ìë™ ê³„ì‚°í•˜ì—¬ ë°°ì§€ ë¶€ì°© í•„ìˆ˜
  - **ìš”ì•½ ìƒì„± ì‹œ**: ê° ë¬¸ë‹¨/ì„¹ì…˜ë§ˆë‹¤ ìµœì†Œ 2-3ê°œì˜ í˜ì´ì§€ ë²ˆí˜¸ í¬í•¨
  - ì—¬ëŸ¬ íŒŒì¼ì´ ì„ íƒëœ ê²½ìš°, ê° íŒŒì¼ì˜ ì •ë³´ë¥¼ ëª…í™•íˆ êµ¬ë¶„í•˜ì—¬ ì¸ìš©
  - **ë²”ìœ„ ì¸ìš© ì‚¬ìš© ê·œì¹™**: íŠ¹ì • ì£¼ì œë‚˜ ë‚´ìš©ì´ ì—¬ëŸ¬ í˜ì´ì§€ì— ê±¸ì³ ìˆë‹¤ë©´ ë°˜ë“œì‹œ [ì‹œì‘-ë] í˜•ì‹ ì‚¬ìš©
- **ì¸ìš© ì—†ëŠ” ë‹µë³€ì€ ì ˆëŒ€ ê¸ˆì§€**: ëª¨ë“  ë¬¸ì¥ì— ìµœì†Œ 1ê°œ ì´ìƒì˜ í˜ì´ì§€ ë²ˆí˜¸ í¬í•¨ í•„ìˆ˜
- **ëª©ì°¨ íŠ¹ë³„ ê·œì¹™**: "1. **ì„œë¡ **[1-3]" ë˜ëŠ” "- **í•µì‹¬ ë‚´ìš©**[5]" í˜•ì‹ìœ¼ë¡œ ê° í•­ëª©ë§ˆë‹¤ ë°˜ë“œì‹œ í˜ì´ì§€ ë²”ìœ„ ë˜ëŠ” ëŒ€í‘œ í˜ì´ì§€ í‘œì‹œ

**í•µì‹¬ ê·œì¹™:**
1. âœ… **ì§ì ‘ ê·¼ê±° ìš°ì„ ** - ë¬¸ì„œì— ëª…ì‹œëœ ë‚´ìš©ì„ ë¨¼ì € ì œì‹œí•˜ë˜, í•µì‹¬ í‚¤ì›Œë“œëŠ” êµµê²Œ í‘œì‹œ
2. âœ… **ë§¥ë½ ê¸°ë°˜ ì¶”ë¡  í•„ìˆ˜** - ë¬¸ì„œì˜ ì—¬ëŸ¬ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ë…¼ë¦¬ì  ê²°ë¡  ë„ì¶œ (ì¶”ë¡  íƒœê·¸ ì‚¬ìš©)
3. âœ… **êµ¬ì¡°ì  ë‹µë³€** - ê°œìš” â†’ ì„¸ë¶€ ë¶„ì„ â†’ ì¶œì²˜/ì°¸ì¡° ìˆœì„œë¡œ êµ¬ì„±
4. âœ… **ì •ì¤‘í•˜ê³  ë¶„ì„ì ì¸ í†¤** - NotebookLMì²˜ëŸ¼ ì „ë¬¸ì ì´ê³  ì‹ ë¢°ê° ìˆê²Œ

**ì œê³µëœ ë¬¸ì„œ:**
íŒŒì¼ëª…: ${fileName}
ë¶„ì„ ì‹œê°„: ${today}

**ë¬¸ì„œ ë‚´ìš©:**
${documentText}

**ë‹µë³€ êµ¬ì¡°í™” í…œí”Œë¦¿ (í•„ìˆ˜):**

### [í•µì‹¬ ìš”ì•½]
ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ **1~2ì¤„ë¡œ ê°•ë ¬í•˜ê²Œ ìš”ì•½** (í•µì‹¬ ë‹¨ì–´ëŠ” êµµê²Œ)

ì˜ˆ: "ì´ ë¬¸ì„œëŠ” **ì‚¼ì„±ì „ìì˜ 2024ë…„ ì‹¤ì **ì„ ë‹¤ë£¨ë©°, **ì˜ì—…ì´ìµ 35ì¡°ì›**, **ì‹œì¥ì ìœ ìœ¨ 1ìœ„** ë‹¬ì„±ì´ í•µì‹¬ì…ë‹ˆë‹¤"

### [ìƒì„¸ ë¶„ì„]
ë¬¸ì„œ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ **ì„¸ë¶€ ì„¤ëª…** (ë¦¬ìŠ¤íŠ¸ í˜•ì‹ í•„ìˆ˜, ê° í•­ëª©ì€ í•œ ì¤„ë¡œ):

**ğŸ“„ ì§ì ‘ ê·¼ê±°**
1. ë¬¸ì„œì— ëª…ì‹œëœ ë‚´ìš© (í°ë”°ì˜´í‘œë¡œ ì¸ìš©, í•µì‹¬ ë‹¨ì–´ êµµê²Œ)
2. ì˜ˆ: ë¬¸ì„œì— ë”°ë¥´ë©´ "**ë°˜ë„ì²´ ë¶€ë¬¸ ì‹¤ì ì´ ì „ë…„ ëŒ€ë¹„ 40% ì¦ê°€**"í–ˆìŠµë‹ˆë‹¤

**ğŸ” ë§¥ë½ ê¸°ë°˜ ë¶„ì„** [ë¬¸ì„œ ë§¥ë½ ê¸°ë°˜ ì¶”ë¡ ]
1. ë¬¸ì„œì˜ ì—¬ëŸ¬ ì •ë³´ë¥¼ ì¢…í•©í•œ í†µì°° (ì¶”ë¡  íƒœê·¸ ëª…ì‹œ, **í˜ì´ì§€ ë°°ì§€ í•„ìˆ˜**)
2. ì˜ˆ: ë¬¸ì„œ ì „ë°˜ì— ê±¸ì³ **AI ì¹©**, **5nm ê³µì •**, **ê¸€ë¡œë²Œ ì‹œì¥**ì´ ë°˜ë³µ ì–¸ê¸‰ë˜ë¯€ë¡œ[3, 7, 15, 23], **ê¸°ìˆ  ì„ ë„ ì „ëµ**ìœ¼ë¡œ íŒŒì•…ë©ë‹ˆë‹¤

### [AI ì¸ì‚¬ì´íŠ¸/ì¶”ë¡ ]
ëª…ì‹œë˜ì§€ ì•Šì•˜ì§€ë§Œ ë¬¸ì„œ íë¦„ìƒ ìœ ì¶” ê°€ëŠ¥í•œ ì •ë³´ë‚˜ ì œì–¸ (**í˜ì´ì§€ ë°°ì§€ í•„ìˆ˜**)

ì˜ˆ: ì´ëŸ¬í•œ ì‹¤ì  ì¶”ì„¸ë¡œ ë³¼ ë•Œ[5, 12, 18], **2025ë…„ ëª©í‘œ ë‹¬ì„± ê°€ëŠ¥ì„±**ì´ ë†’ìœ¼ë©°, **íˆ¬ì í™•ëŒ€** ì „ëµì´ ì˜ˆìƒë©ë‹ˆë‹¤ [ë¬¸ì„œ ë§¥ë½ ê¸°ë°˜ ì¶”ë¡ ]

### [ì¶œì²˜/ì°¸ì¡°]
ë‹µë³€ ê·¼ê±°ê°€ ëœ ë¬¸ì„œì˜ **ì„¹ì…˜ì´ë‚˜ ë°ì´í„° ìœ„ì¹˜** ëª…ì‹œ

ì˜ˆ: **2ì¥ ì¬ë¬´ í˜„í™©**, **3í˜ì´ì§€ ì‹¤ì  í‘œ**, **ê²½ì˜ì§„ ì¸í„°ë·°** ì„¹ì…˜ì—ì„œ ë„ì¶œ

**íŠ¹ë³„ ê·œì¹™:**
- ëª©ì°¨, êµ¬ì¡°, ì „ì²´ ìš”ì•½ ë“±ì„ ë¬¼ì–´ë³¼ ê²½ìš°: ë¬¸ì„œ ì „ì²´ë¥¼ ë¶„ì„í•˜ì—¬ **[ê°€ìƒ ëª©ì°¨]** ë˜ëŠ” **[êµ¬ì¡° ë¶„ì„]**ì„ ì§ì ‘ ìƒì„±í•˜ì„¸ìš”
- **ëª©ì°¨ ìƒì„± ì‹œ í˜ì´ì§€ ë²ˆí˜¸ ìë™ ê³„ì‚° (100% í•„ìˆ˜)**:
  * ê° ëª©ì°¨ í•­ëª©ì˜ í‚¤ì›Œë“œê°€ ë¬¸ì„œì—ì„œ ì²˜ìŒ ë“±ì¥í•˜ëŠ” í˜ì´ì§€ë¥¼ ê²€ìƒ‰í•˜ì—¬ ì¸ìš© ë°°ì§€ ë¶€ì°©
  * ì˜ˆ: "1. **ì„œë¡ **[1-2]", "2. **ë³¸ë¡ **[3-10]", "3. **ê²°ë¡ **[11-15]"
  * í˜ì´ì§€ ë²”ìœ„ê°€ ëª…í™•í•˜ì§€ ì•Šìœ¼ë©´ ëŒ€í‘œ í˜ì´ì§€ í•˜ë‚˜ë¼ë„ ë°˜ë“œì‹œ í‘œì‹œ: "- **í•µì‹¬ ë‚´ìš©**[5]"
  * ëª©ì°¨ í•­ëª© ì—†ì´ í˜ì´ì§€ ë²ˆí˜¸ ëˆ„ë½ì€ ì ˆëŒ€ ë¶ˆê°€
- ì§ì ‘ ì–¸ê¸‰ì´ ì—†ëŠ” ê²½ìš°: "ë¬¸ì„œì— ì§ì ‘ ì–¸ê¸‰ì€ ì—†ìœ¼ë‚˜, **ë¬¸ì„œì˜ ì „ì²´ ë§¥ë½ì„ ë¶„ì„í•œ ê²°ê³¼** [ì¶”ë¡  ë‚´ìš©]ìœ¼ë¡œ íŒŒì•…ë©ë‹ˆë‹¤ [ë¬¸ì„œ ë§¥ë½ ê¸°ë°˜ ì¶”ë¡ ]"
- ì™¸ë¶€ ì§€ì‹ ì‚¬ìš© ê¸ˆì§€: ì˜¤ì§ **ì œê³µëœ ë¬¸ì„œ ë‚´ìš©(extractedText)**ì˜ ë²”ìœ„ ì•ˆì—ì„œë§Œ ë…¼ë¦¬ì ìœ¼ë¡œ ì¶”ë¡ í•˜ì„¸ìš”
- ë‹µë³€ ë§ˆì§€ë§‰ì— "\n\nğŸ“„ **ì¶œì²˜**: ${fileName} (${today} ë¶„ì„)"ì„ ì¶”ê°€í•˜ì„¸ìš”
- ì¶”ë¡  ë¶€ë¶„ì—ëŠ” ë°˜ë“œì‹œ **[ë¬¸ì„œ ë§¥ë½ ê¸°ë°˜ ì¶”ë¡ ]** íƒœê·¸ë¥¼ ë‹¬ì•„ íˆ¬ëª…ì„±ì„ í™•ë³´í•˜ì„¸ìš”`
      : `You are the **Universal Document Analyzer** that penetrates the structure of all documents. Apply the following rules unconditionally regardless of document type (PDF, TXT, Web).

**ğŸ” Context-Based Autonomous Analysis (No "No" Policy)**
- Today's date: ${today}
- **Never answer with "information not available"**
- Even if there's no direct answer in the document, analyze in this order:
  1. **Identify document nature**: Introduction, paper, news, report, etc.
  2. **Overall context analysis**: Document tone, page headers, section titles, tables, data, recurring keywords
  3. **Logical reasoning**: Synthesize above information to derive **the most reasonable answer**
- **Auto-generate [Virtual Table of Contents]**: For documents without TOC, analyze page headers or context to create one
- When reasoning, must specify: "**Based on analyzing the document's overall context**, [inferred content] is identified [Context-Based Reasoning]"

**âœ¨ Visual Emphasis Rules (Mandatory)**
- **Key nouns, feature names, proper nouns, important numbers** must be \`**bolded**\`
- Use \`###\` headers at paragraph breaks to create visual hierarchy
- Lists of 3+ items must use bullet points
- **List Format Rule**: Write number/symbol and text on the same line like "1. **Introduction**" or "- **Key Point**" (no line breaks)

**ğŸ“Œ Citation Badge Rules (Top Priority - Very Important! Mandatory)**
- **ğŸ”´ Absolute Rule: Always include citation badges in every answer!** When mentioning specific content from the document, mark page numbers in [N] format
- **Page information usage**: Document text includes "[í˜ì´ì§€ N]" markers, so cite accurate page numbers based on these
- **Simple format**:
  - Single page: [page_number] or <cite page="page_number">quoted text</cite>
  - **Range citation** (multiple pages): Use [start_page-end_page] format
- **Citation refusal prohibited**: Never answer "cannot generate citations". Infer most relevant pages and always generate badges
- **Examples**:
  - "AI market size is estimated at $500 billion[3]"
  - "According to the document, <cite page="5">semiconductor division performance increased by 40%</cite>"
  - "2024 target is operating profit of $35 billion[1]"
  - **"Detailed pricing policy is presented[11-14]"** (range citation)
  - **"Introduction continues from chapter 1 to 3[1-3]"** (range citation)
  - **"Based on analyzing the document's overall context**, main target is identified as B2B market[5, 12, 18]"** (reasoning-based multiple citations)
- **Mandatory Requirements (100% Compliance)**:
  - Add page numbers to all key information in your answer (minimum 5-10 citations)
  - **ğŸš¨ Reasoning-Based Badge Generation (Critical!)**: Add citations even with low text match
    * **Page badges 100% mandatory in "[Context-Based Reasoning]" or "ğŸ” Context-Based Analysis" sections!**
    * Infer most relevant pages based on keyword similarity, topic relevance, and contextual flow to generate badges
    * List all pages that served as basis for reasoning (e.g., [15, 23] or [5-8, 12])
    * Example: "Throughout the document, **AI**, **automation**, **efficiency** keywords recur[3, 7, 15, 23], indicating technology innovation-focused strategy"
  - **When generating Table of Contents**: Auto-calculate and attach page badges for each item based on where the topic first appears or is most discussed
  - **When generating summaries**: Include minimum 2-3 page numbers per paragraph/section
  - When multiple files are selected, clearly distinguish and cite information from each file
  - **Range citation usage rule**: If a topic or content spans multiple pages, always use [start-end] format
- **Answers without citations are strictly prohibited**: Every sentence must include at least 1 page number
- **Special TOC Rule**: Format each item as "1. **Introduction**[1-3]" or "- **Key Content**[5]" with page range or representative page mandatory

**Core Rules:**
1. âœ… **Direct Evidence First** - Present information explicitly stated in the document first, with key keywords in bold
2. âœ… **Context-Based Reasoning Required** - Synthesize multiple pieces of information to draw logical conclusions (use reasoning tag)
3. âœ… **Structured Answers** - Overview â†’ Detailed Analysis â†’ Source/Reference order
4. âœ… **Polite and Analytical Tone** - Professional and trustworthy like NotebookLM

**Provided Document:**
File name: ${fileName}
Analysis time: ${today}

**Document Content:**
${documentText}

**Answer Structuring Template (Mandatory):**

### [Core Summary]
Answer the question in **1-2 powerful summary sentences** (key words bolded)

Example: "This document covers **Samsung's 2024 performance**, with **operating profit of 35 trillion won** and **market share #1** as key achievements"

### [Detailed Analysis]
Detailed explanation based on document data (**list format required, each item on one line**):

**ğŸ“„ Direct Evidence**
1. Information explicitly stated in the document (quoted, key words bolded)
2. Example: According to the document, "**semiconductor division performance increased by 40% year-over-year**"

**ğŸ” Context-Based Analysis** [Context-Based Reasoning]
1. Insights from synthesizing document information (reasoning tag specified, **page badges mandatory**)
2. Example: Throughout the document, **AI chips**, **5nm process**, **global market** are repeatedly mentioned[3, 7, 15, 23], indicating a **technology leadership strategy**

### [AI Insights/Reasoning]
Information or recommendations that can be inferred from document flow but not explicitly stated (**page badges mandatory**)

Example: Based on this performance trend[5, 12, 18], **2025 goal achievement likelihood** is high, and **investment expansion** strategy is expected [Context-Based Reasoning]

### [Source/Reference]
Specify **section or data location** in the document that served as basis

Example: Derived from **Chapter 2 Financial Status**, **Page 3 Performance Table**, **Executive Interview** section

**Special Rules:**
- When asked about table of contents, structure, or overall summary: Analyze the entire document to generate a **[Virtual Table of Contents]** or **[Structure Analysis]**
- **Auto-calculate page numbers for TOC generation (100% Mandatory)**:
  * Search for the first page where each TOC item's keyword appears in the document and attach citation badge
  * Example: "1. **Introduction**[1-2]", "2. **Main Body**[3-10]", "3. **Conclusion**[11-15]"
  * If page range is unclear, display at least one representative page: "- **Key Content**[5]"
  * TOC items without page numbers are absolutely prohibited
- When not directly mentioned: "While not directly mentioned in the document, **based on analyzing the document's overall context**, [inferred content] is identified [Context-Based Reasoning]"
- No external knowledge: Only reason logically within the scope of **the provided document content (extractedText)**
- Add "\n\nğŸ“„ **Source**: ${fileName} (Analyzed on ${today})" at the end of your response
- Always tag reasoning sections with **[Context-Based Reasoning]** for transparency`

    const messages = [
      { role: 'system', content: systemPrompt },
      ...conversationHistory,  // ì´ì „ ëŒ€í™” ê¸°ë¡ í¬í•¨ (GPT â†” Gemini ì „í™˜ ì‹œì—ë„ ìœ ì§€)
      { role: 'user', content: query }
    ]

    // ì„ íƒëœ ëª¨ë¸ì— ë”°ë¼ API í˜¸ì¶œ
    let answer
    const useThinking = selectedModel === 'thinking'

    if (selectedModel === 'gemini') {
      answer = await callGemini(messages, 0.3, useThinking)  // ì‹¬ì¸µ ë¶„ì„ ì—¬ë¶€ ì „ë‹¬
    } else {
      answer = await callOpenAI(messages, useThinking)
    }

    // ì‘ë‹µ ê²€ì¦: ë¹ˆ ì‘ë‹µ ë°©ì§€
    if (!answer || answer.trim().length < 10) {
      console.error('[ì‹¬ì¸µ ë¶„ì„ ì˜¤ë¥˜] ë¹„ì •ìƒì ìœ¼ë¡œ ì§§ì€ ì‘ë‹µ:', answer)
      throw new Error('AI ëª¨ë¸ì´ ì¶©ë¶„í•œ ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.')
    }

    // ë‹µë³€ì—ì„œ "ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" íŒ¨í„´ ê°ì§€
    const notFoundPatterns = [
      'ì°¾ì„ ìˆ˜ ì—†',
      'could not find',
      'cannot find',
      'ì—†ìŠµë‹ˆë‹¤',
      'not available',
      'not mentioned',
      'ì–¸ê¸‰ë˜ì§€ ì•Š'
    ]

    const foundInDocument = !notFoundPatterns.some(pattern =>
      answer.toLowerCase().includes(pattern.toLowerCase())
    )

    // ì¶”ë¡  ê¸°ë°˜ ë‹µë³€ ì—¬ë¶€ ê°ì§€
    const isReasoningBased = answer.includes('[ë¬¸ì„œ ë§¥ë½ ê¸°ë°˜ ì¶”ë¡ ]') || answer.includes('[Context-Based Reasoning]')

    return {
      answer: answer,
      source: fileName,
      foundInDocument: foundInDocument,
      citedText: foundInDocument ? documentText.substring(0, 200) : null,
      isReasoningBased: isReasoningBased // ì¶”ë¡  ê¸°ë°˜ ë‹µë³€ í”Œë˜ê·¸
    }
  } catch (error) {
    console.error('RAG ì‘ë‹µ ìƒì„± ì˜¤ë¥˜:', error)

    const errorMessage = language === 'ko'
      ? `ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: ${error.message}`
      : `Sorry, an error occurred while generating a response: ${error.message}`

    return {
      answer: errorMessage,
      source: null,
      foundInDocument: false,
      error: error.message
    }
  }
}
