import { extractTextFromParsedData } from '../utils/fileParser'
import { GoogleGenerativeAI } from '@google/generative-ai'

const OPENAI_API_KEY = import.meta.env.VITE_OPENAI_API_KEY
const GEMINI_API_KEY = import.meta.env.VITE_GEMINI_API_KEY

// GPT ëª¨ë¸ ì„¤ì • (2026ë…„ 1ì›” ê¸°ì¤€ ìµœì‹ )
const GPT_MODELS = {
  INSTANT: 'gpt-5.2-chat-latest',  // ë¹ ë¥¸ ì‘ë‹µ (GPT-5.2 Instant - ì ì‘í˜• ì¶”ë¡ )
  THINKING: 'gpt-5.2',             // ì‹¬ì¸µ ì¶”ë¡  (GPT-5.2 Thinking - ê³ ê¸‰ ì¶”ë¡ )
  MINI: 'gpt-4o-mini'              // ì´ˆì €ë¹„ìš©/ì´ˆê³ ì† (ì œì•ˆ/í•„í„°ë§ìš©)
}

// Gemini ëª¨ë¸ ì„¤ì • (2025ë…„ 12ì›” ê¸°ì¤€ ìµœì‹ )
const GEMINI_MODEL = 'gemini-3-flash-preview' // Gemini 3 Flash (ê³µì‹ Preview ë²„ì „ - 2025.12.17 ì¶œì‹œ)

// Gemini AI ì´ˆê¸°í™”
const genAI = GEMINI_API_KEY ? new GoogleGenerativeAI(GEMINI_API_KEY) : null

// ì–¸ì–´ ê°ì§€ (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
export const detectLanguage = (text) => {
  // í•œê¸€ì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ í•œêµ­ì–´
  const koreanRegex = /[\uAC00-\uD7AF\u1100-\u11FF\u3130-\u318F]/
  return koreanRegex.test(text) ? 'ko' : 'en'
}

// ë‹¨ìˆœ ì¸ì‚¬ë§/ì˜ë¯¸ ì—†ëŠ” ì…ë ¥ì¸ì§€ í™•ì¸ (API ë¹„ìš© ì ˆê°ìš©)
export const isMeaninglessQuery = (query) => {
  if (!query || query.trim().length < 2) return true

  const greetings = [
    'ì•ˆë…•', 'ë°˜ê°€ì›Œ', 'í•˜ì´', 'hi', 'hello', 'í—¬ë¡œ', 'ì¢‹ì€ ì•„ì¹¨', 'ì¢‹ì€ ì €ë…',
    'ì–´ë–»ê²Œ ì§€ë‚´', 'ì˜ ì§€ë‚´', 'ë­í•´', 'ë­í•˜ë‹ˆ', 'ê³ ë§ˆì›Œ', 'ê°ì‚¬', 'thank',
    'ì˜í–ˆì–´', 'ì¢‹ì•„', 'ê´œì°®ì•„', 'good', 'great', 'thanks', 'bye', 'ì•ˆë…•íˆ',
    'ì˜ê°€', 'ë˜ ë´', 'í…ŒìŠ¤íŠ¸', 'test', 'ì˜¤ëŠ˜ ë‚ ì”¨', 'ë‚ ì”¨'
  ]

  const queryLower = query.toLowerCase().trim()
  // ë„ˆë¬´ ì§§ê±°ë‚˜ ë¦¬ìŠ¤íŠ¸ì— ìˆëŠ” ì¸ì‚¬ë§ì¸ ê²½ìš°
  return queryLower.length < 2 || greetings.some(greeting => queryLower === greeting || queryLower.includes(greeting) && queryLower.length < 5)
}

// OpenAI API í˜¸ì¶œ
// GPT-5.2ëŠ” temperatureë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŒ (ê³ ì •ê°’ 1)
const callOpenAI = async (messages, useThinking = false, useMini = false) => {
  try {
    let model = useThinking ? GPT_MODELS.THINKING : GPT_MODELS.INSTANT
    if (useMini) model = GPT_MODELS.MINI

    // GPT-5.2ëŠ” temperature, top_p, presence_penalty, frequency_penalty ëª¨ë‘ ë¯¸ì§€ì›
    // ë‚´ë¶€ì ìœ¼ë¡œ temperature=1 ê³ ì •
    // ì‹¬ì¸µ ë¶„ì„ ëª¨ë“œëŠ” ë” ê¸´ ì‘ë‹µ í—ˆìš© (4000 í† í°)
    const requestBody = {
      model: model,
      messages: messages,
      max_completion_tokens: useThinking ? 4000 : 2000  // ì‹¬ì¸µ ë¶„ì„ì€ 4000, ì¼ë°˜ì€ 2000
    }

    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${OPENAI_API_KEY}`
      },
      body: JSON.stringify(requestBody),
      signal: AbortSignal.timeout(120000)  // 120ì´ˆ íƒ€ì„ì•„ì›ƒ (ì‹¬ì¸µ ë¶„ì„ìš©)
    })

    if (!response.ok) {
      const error = await response.json()
      throw new Error(error.error?.message || 'OpenAI API í˜¸ì¶œ ì‹¤íŒ¨')
    }

    const data = await response.json()

    // ì‘ë‹µ ê¸¸ì´ í™•ì¸ ë° ë¡œê¹…
    const content = data.choices[0].message.content
    console.log(`[OpenAI ${useThinking ? 'Thinking' : 'Instant'}] ì‘ë‹µ ê¸¸ì´: ${content.length}ì`)

    return content
  } catch (error) {
    console.error('OpenAI API ì˜¤ë¥˜:', error)

    // ì‚¬ìš©ì ì¹œí™”ì  ì—ëŸ¬ ë©”ì‹œì§€ ì²˜ë¦¬ (í•œê¸€í™”)
    const errMessage = error.message || ''
    if (errMessage.includes('rate_limit')) {
      throw new Error('OpenAI API í˜¸ì¶œ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.')
    } else if (errMessage.includes('insufficient_quota')) {
      throw new Error('OpenAI API í¬ë ˆë”§ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. ê²°ì œ ìˆ˜ë‹¨ì´ë‚˜ í•œë„ë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.')
    } else if (errMessage.includes('context_length_exceeded')) {
      throw new Error('ì…ë ¥ ì–‘ì´ ë„ˆë¬´ ë§ì•„ ëª¨ë¸ì˜ ì»¨í…ìŠ¤íŠ¸ ì œí•œì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ë¬¸ì„œ ì„ íƒì„ ì¤„ì—¬ì£¼ì„¸ìš”.')
    } else if (errMessage.includes('invalid_api_key')) {
      throw new Error('OpenAI API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. í™˜ê²½ ë³€ìˆ˜ë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.')
    }

    throw error
  }
}

// Gemini API í˜¸ì¶œ
const callGemini = async (messages, temperature = 0.3, isDeepAnalysis = false) => {
  try {
    if (!genAI) {
      throw new Error('Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤')
    }

    const model = genAI.getGenerativeModel({ model: GEMINI_MODEL })

    // messages ë°°ì—´ì„ Gemini í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    // GeminiëŠ” system roleì„ ì§ì ‘ ì§€ì›í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ, system ë©”ì‹œì§€ë¥¼ ì²« user ë©”ì‹œì§€ì— í¬í•¨
    const systemMessage = messages.find(m => m.role === 'system')
    const conversationMessages = messages.filter(m => m.role !== 'system')

    // Gemini ëŒ€í™” ê¸°ë¡ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    const geminiContents = []

    // ì²« ë²ˆì§¸ ë©”ì‹œì§€ì— system í”„ë¡¬í”„íŠ¸ í¬í•¨
    if (conversationMessages.length > 0) {
      const firstUserMsg = conversationMessages[0]
      const contentWithSystem = systemMessage
        ? `${systemMessage.content}\n\nì‚¬ìš©ì ì§ˆë¬¸: ${firstUserMsg.content}`
        : firstUserMsg.content

      geminiContents.push({
        role: 'user',
        parts: [{ text: contentWithSystem }]
      })

      // ë‚˜ë¨¸ì§€ ëŒ€í™” ê¸°ë¡ ì¶”ê°€ (user â†” assistant ë²ˆê°ˆì•„ê°€ë©°)
      for (let i = 1; i < conversationMessages.length; i++) {
        const msg = conversationMessages[i]
        geminiContents.push({
          role: msg.role === 'assistant' ? 'model' : 'user',  // GeminiëŠ” 'model' role ì‚¬ìš©
          parts: [{ text: msg.content }]
        })
      }
    } else if (systemMessage) {
      // ëŒ€í™” ê¸°ë¡ì´ ì—†ê³  system ë©”ì‹œì§€ë§Œ ìˆëŠ” ê²½ìš°
      geminiContents.push({
        role: 'user',
        parts: [{ text: systemMessage.content }]
      })
    }

    const result = await model.generateContent({
      contents: geminiContents,
      generationConfig: {
        temperature: temperature,
        maxOutputTokens: isDeepAnalysis ? 4000 : 2000,  // ì‹¬ì¸µ ë¶„ì„ì€ 4000, ì¼ë°˜ì€ 2000
      },
    })

    const response = result.response
    const content = response.text()

    // ì‘ë‹µ ê¸¸ì´ í™•ì¸ ë° ë¡œê¹…
    console.log(`[Gemini ${isDeepAnalysis ? 'Deep Analysis' : 'Standard'}] ì‘ë‹µ ê¸¸ì´: ${content.length}ì, ëŒ€í™” ê¸°ë¡: ${conversationMessages.length}ê°œ`)

    return content
  } catch (error) {
    console.error('Gemini API ì˜¤ë¥˜:', error)

    // ì‚¬ìš©ì ì¹œí™”ì  ì—ëŸ¬ ë©”ì‹œì§€ ì²˜ë¦¬ (í•œê¸€í™”)
    const errMessage = error.message || ''

    if (errMessage.includes('404') || errMessage.includes('not found')) {
      throw new Error(`ì§€ì›í•˜ì§€ ì•ŠëŠ” Gemini ëª¨ë¸ ì„¤ì •ì…ë‹ˆë‹¤ (${GEMINI_MODEL}). ëª¨ë¸ëª…ì„ í™•ì¸í•´ì£¼ì„¸ìš”.`)
    } else if (errMessage.includes('API key')) {
      throw new Error('Gemini API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•Šê±°ë‚˜ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í™˜ê²½ ë³€ìˆ˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.')
    } else if (errMessage.includes('quota') || errMessage.includes('limit') || errMessage.includes('consumed')) {
      throw new Error('Gemini API ì‚¬ìš©ëŸ‰ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ê±°ë‚˜ ë‹¤ë¥¸ ëª¨ë¸ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.')
    } else if (errMessage.includes('permission')) {
      throw new Error('Gemini API í‚¤ì— í•´ë‹¹ ëª¨ë¸ ì‚¬ìš© ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤.')
    } else if (errMessage.includes('exceed') && errMessage.includes('token')) {
      throw new Error('ì…ë ¥ ë°ì´í„°ê°€ ë„ˆë¬´ ì»¤ì„œ í† í° ì œí•œì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ì„ íƒëœ ë¬¸ì„œì˜ ì–‘ì„ ì¤„ì´ê±°ë‚˜ ë©”ì‹œì§€ ê¸¸ì´ë¥¼ ì¤„ì—¬ì£¼ì„¸ìš”.')
    } else if (errMessage.includes('safety') || errMessage.includes('finish_reason: SAFETY')) {
      throw new Error('ì•ˆì „ ê°€ì´ë“œë¼ì¸ì— ë”°ë¥¸ ì°¨ë‹¨ìœ¼ë¡œ ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì§ˆë¬¸ ë‚´ìš©ì„ ê²€í† í•´ ì£¼ì„¸ìš”.')
    }

    throw error
  }
}

// ë¬¸ì„œ ìë™ ìš”ì•½ ìƒì„± (Instant ëª¨ë¸ ì‚¬ìš© - ë¹ ë¥¸ ìš”ì•½)
export const generateDocumentSummary = async (documentContext, language = 'ko') => {
  try {
    if (!documentContext || !documentContext.parsedData) {
      return null
    }

    const documentText = extractTextFromParsedData(documentContext.parsedData)
    const fileName = documentContext.name || 'ë¬¸ì„œ'

    // ìš”ì•½ì´ ë„ˆë¬´ ì§§ìœ¼ë©´ ìŠ¤í‚µ
    if (!documentText || documentText.length < 100) {
      return null
    }

    const summaryPrompt = language === 'ko'
      ? `ë‹¤ìŒ ë¬¸ì„œì˜ í•µì‹¬ ë‚´ìš©ì„ 3-5ì¤„ë¡œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”. ë¬¸ì„œì— ëª…ì‹œëœ ë‚´ìš©ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.

**ë¬¸ì„œ ì œëª©:** ${fileName}

**ë¬¸ì„œ ë‚´ìš©:**
${documentText.substring(0, 3000)}

**ìš”ì•½ ê·œì¹™:**
- 3-5ê°œì˜ í•µì‹¬ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±
- ë¬¸ì„œì˜ ì£¼ìš” ì£¼ì œì™€ í•µì‹¬ ë‚´ìš© í¬í•¨
- ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ
- ë¶ˆí•„ìš”í•œ ì¸ì‚¬ë§ ì—†ì´ ë°”ë¡œ ìš”ì•½ ì‹œì‘`
      : `Please summarize the following document in 3-5 concise sentences. Only use information from the document.

**Document Title:** ${fileName}

**Document Content:**
${documentText.substring(0, 3000)}

**Summary Rules:**
- Write 3-5 key sentences
- Include main topics and core content
- Clear and concise
- Start directly without greetings`

    const messages = [
      { role: 'system', content: summaryPrompt },
      { role: 'user', content: language === 'ko' ? 'ì´ ë¬¸ì„œë¥¼ ìš”ì•½í•´ì£¼ì„¸ìš”.' : 'Please summarize this document.' }
    ]

    const summary = await callOpenAI(messages, false) // Instant ëª¨ë¸ (GPT-5.2)
    return summary

  } catch (error) {
    console.error('ë¬¸ì„œ ìš”ì•½ ìƒì„± ì˜¤ë¥˜:', error)
    return null
  }
}

// ë¬¸ì„œ ê¸°ë°˜ ë™ì  í˜ë¥´ì†Œë‚˜ ë¶„ì„ (ì¡°ì§/íšŒì‚¬ëª…, ë¬¸ì„œ ìœ í˜•, ì¶”ì²œ í˜ë¥´ì†Œë‚˜ ì¶”ì¶œ)
export const analyzeDocumentForPersonas = async (documentContext, language = 'ko') => {
  try {
    if (!documentContext || !documentContext.parsedData) {
      return null
    }

    const documentText = extractTextFromParsedData(documentContext.parsedData)
    const fileName = documentContext.name || 'ë¬¸ì„œ'

    // ë¬¸ì„œê°€ ë„ˆë¬´ ì§§ìœ¼ë©´ ìŠ¤í‚µ
    if (!documentText || documentText.length < 100) {
      return null
    }

    const personaPrompt = language === 'ko'
      ? `ë‹¤ìŒ ë¬¸ì„œë¥¼ ë¶„ì„í•˜ì—¬ ì¡°ì§/íšŒì‚¬ëª…, ë¬¸ì„œ ìœ í˜•, ê·¸ë¦¬ê³  ì´ ë¬¸ì„œì— ì í•©í•œ AI í˜ë¥´ì†Œë‚˜ 3ê°œë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

**ë¬¸ì„œ ì œëª©:** ${fileName}

**ë¬¸ì„œ ë‚´ìš©:**
${documentText.substring(0, 4000)}

**ë¶„ì„ ìš”êµ¬ì‚¬í•­:**
1. **detectedEntity**: ë¬¸ì„œì—ì„œ ì–¸ê¸‰ëœ ì£¼ìš” ì¡°ì§/íšŒì‚¬ëª… (ì˜ˆ: "ì—ì´ë¹„ë”©", "ì‚¼ì„±ì „ì", "ë„¤ì´ë²„")
2. **documentType**: ë¬¸ì„œì˜ ì„±ê²©/ìœ í˜• (ì˜ˆ: "ì„œë¹„ìŠ¤ ì†Œê°œì„œ", "ì œí’ˆ ì¹´íƒˆë¡œê·¸", "ì—°êµ¬ ë³´ê³ ì„œ", "ë§ˆì¼€íŒ… ìë£Œ", "ê¸°ìˆ  ë¬¸ì„œ")
3. **suggestedPersonas**: ì´ ë¬¸ì„œì— ë§ëŠ” AI í˜ë¥´ì†Œë‚˜ 3ê°œë¥¼ ë°°ì—´ë¡œ ìƒì„±
   - ê° í˜ë¥´ì†Œë‚˜ëŠ” { label: "í˜ë¥´ì†Œë‚˜ ì´ë¦„", prompt: "ìƒì„¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸" } í˜•ì‹
   - ì˜ˆ: [
       {
         "label": "ì—ì´ë¹„ë”© ìš´ì˜ì",
         "prompt": "ë‹¹ì‹ ì€ ì—ì´ë¹„ë”© ì„œë¹„ìŠ¤ì˜ ìˆ˜ì„ ìš´ì˜ìì…ë‹ˆë‹¤. ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê³ ê°ì˜ ë¬¸ì˜ì— ì¹œì ˆí•˜ê³  ì „ë¬¸ì ìœ¼ë¡œ ì‘ëŒ€í•˜ê³ , ìš°ë¦¬ ì„œë¹„ìŠ¤ì˜ ì¥ì ì„ ë¶€ê°í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”."
       },
       {
         "label": "ë„ì… ê²€í†  ì¤‘ì¸ ë§ˆì¼€í„°",
         "prompt": "ë‹¹ì‹ ì€ ì—ì´ë¹„ë”© ì„œë¹„ìŠ¤ë¥¼ ë„ì… ê²€í†  ì¤‘ì¸ ë§ˆì¼€íŒ… ë‹´ë‹¹ìì…ë‹ˆë‹¤. ë¬¸ì„œë¥¼ ë¶„ì„í•˜ì—¬ ì„œë¹„ìŠ¤ì˜ ì‹¤ìš©ì„±, ROI, ë„ì… ì‹œ ê³ ë ¤ì‚¬í•­ì„ ì¤‘ë¦½ì  ê´€ì ì—ì„œ í‰ê°€í•˜ì„¸ìš”."
       },
       {
         "label": "ê²½ìŸì‚¬ ë¶„ì„ê°€",
         "prompt": "ë‹¹ì‹ ì€ ê²½ìŸì‚¬ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì´ ë¬¸ì„œë¥¼ ë¶„ì„í•˜ì—¬ í•´ë‹¹ ì„œë¹„ìŠ¤/ì œí’ˆì˜ ê°•ì ê³¼ ì•½ì , ì‹œì¥ í¬ì§€ì…”ë‹, ê²½ìŸ ìš°ìœ„ ìš”ì†Œë¥¼ ê°ê´€ì ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš”."
       }
     ]

**JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µ:**
{
  "detectedEntity": "ì¡°ì§/íšŒì‚¬ëª…",
  "documentType": "ë¬¸ì„œ ìœ í˜•",
  "suggestedPersonas": [
    {
      "label": "í˜ë¥´ì†Œë‚˜ ì´ë¦„",
      "prompt": "ìƒì„¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸"
    }
  ]
}`
      : `Analyze the following document to extract organization/company name, document type, and 3 suitable AI personas.

**Document Title:** ${fileName}

**Document Content:**
${documentText.substring(0, 4000)}

**Analysis Requirements:**
1. **detectedEntity**: Main organization/company name mentioned (e.g., "ABiding", "Samsung", "Naver")
2. **documentType**: Document nature/type (e.g., "Service Introduction", "Product Catalog", "Research Report", "Marketing Material", "Technical Document")
3. **suggestedPersonas**: Generate 3 AI personas suitable for this document as an array
   - Each persona format: { label: "Persona Name", prompt: "Detailed System Prompt" }
   - Example: [
       {
         "label": "ABiding Operator",
         "prompt": "You are the chief operator of ABiding service. Based on the document, respond to customer inquiries in a friendly and professional manner, highlighting our service advantages."
       },
       {
         "label": "Marketing Manager Considering Adoption",
         "prompt": "You are a marketing manager considering adopting ABiding service. Analyze the document to evaluate the service's practicality, ROI, and adoption considerations from a neutral perspective."
       },
       {
         "label": "Competitor Analyst",
         "prompt": "You are a competitor analysis expert. Analyze this document to objectively evaluate the service/product's strengths, weaknesses, market positioning, and competitive advantages."
       }
     ]

**Respond only in JSON format:**
{
  "detectedEntity": "Organization/Company Name",
  "documentType": "Document Type",
  "suggestedPersonas": [
    {
      "label": "Persona Name",
      "prompt": "Detailed System Prompt"
    }
  ]
}`

    const messages = [
      { role: 'system', content: 'You are an expert document analyzer. Always respond with valid JSON only, no additional text.' },
      { role: 'user', content: personaPrompt }
    ]

    const response = await callOpenAI(messages, false) // Instant ëª¨ë¸ (GPT-5.2)

    // JSON íŒŒì‹±
    try {
      const jsonMatch = response.match(/```json\s*([\s\S]*?)\s*```/) || response.match(/\{[\s\S]*\}/)
      const jsonStr = jsonMatch ? (jsonMatch[1] || jsonMatch[0]) : response
      const parsed = JSON.parse(jsonStr)

      console.log('[í˜ë¥´ì†Œë‚˜ ë¶„ì„] ê²°ê³¼:', parsed)
      return parsed
    } catch (e) {
      console.error('[í˜ë¥´ì†Œë‚˜ ë¶„ì„] JSON íŒŒì‹± ì‹¤íŒ¨:', e)
      console.error('[í˜ë¥´ì†Œë‚˜ ë¶„ì„] ì›ë³¸ ì‘ë‹µ:', response)
      return null
    }
  } catch (error) {
    console.error('í˜ë¥´ì†Œë‚˜ ë¶„ì„ ì˜¤ë¥˜:', error)
    return null
  }
}

// ì¶”ì²œ ì§ˆë¬¸ ìƒì„± (Instant ëª¨ë¸ ì‚¬ìš© - ë¹ ë¥¸ ìƒì„±)
export const generateSuggestedQuestions = async (documentContext, language = 'ko') => {
  try {
    if (!documentContext) return []

    let documentText = ''
    let contextName = ''

    if (Array.isArray(documentContext)) {
      documentText = documentContext.map(s => extractTextFromParsedData(s.parsedData)).join('\n\n---\n\n')
      contextName = documentContext.map(s => s.name).join(', ')
    } else if (documentContext.parsedData) {
      documentText = extractTextFromParsedData(documentContext.parsedData)
      contextName = documentContext.name || 'ë¬¸ì„œ'
    }

    // ë¬¸ì„œ ë‚´ìš©ì´ ë„ˆë¬´ ì§§ìœ¼ë©´ ìŠ¤í‚µ
    if (!documentText || documentText.length < 50) {
      return []
    }

    const questionsPrompt = language === 'ko'
      ? `ë‹¤ìŒ ë¬¸ì„œë¥¼ ì½ê³ , ì‚¬ìš©ìê°€ ë¬¼ì–´ë³¼ ë§Œí•œ í¥ë¯¸ë¡œìš´ ì§ˆë¬¸ 4ê°œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
 
 **ë¬¸ì„œ:** ${contextName}
 
 **ë¬¸ì„œ ë‚´ìš©:**
 ${documentText.substring(0, 5000)}

**ì§ˆë¬¸ ìƒì„± ê·œì¹™:**
- ë¬¸ì„œ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ ê°€ëŠ¥í•œ ì§ˆë¬¸ë§Œ ìƒì„±
- ê° ì§ˆë¬¸ì€ 15ì ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ
- ë¬¸ì„œì˜ í•µì‹¬ ë‚´ìš©ì„ ë‹¤ë£¨ëŠ” ì§ˆë¬¸
- JSON ë°°ì—´ í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µ: ["ì§ˆë¬¸1", "ì§ˆë¬¸2", "ì§ˆë¬¸3", "ì§ˆë¬¸4"]
- ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì—†ì´ JSONë§Œ ì¶œë ¥`
      : `Read the following document and generate 4 interesting questions users might ask.

**Document Title:** ${contextName}

**Document Content:**
${documentText.substring(0, 5000)}

**Question Generation Rules:**
- Only generate questions answerable from the document
- Keep each question under 15 words
- Focus on key content
- Respond only in JSON array format: ["Question 1", "Question 2", "Question 3", "Question 4"]
- Output only JSON, no other text`

    const messages = [
      { role: 'system', content: questionsPrompt },
      { role: 'user', content: language === 'ko' ? 'ì§ˆë¬¸ 4ê°œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.' : 'Generate 4 questions.' }
    ]

    const response = await callOpenAI(messages, false) // Instant ëª¨ë¸ (GPT-5.2)

    // JSON íŒŒì‹± ì‹œë„
    try {
      const questions = JSON.parse(response)
      if (Array.isArray(questions) && questions.length > 0) {
        return questions.slice(0, 4)
      }
    } catch (e) {
      console.warn('ì§ˆë¬¸ JSON íŒŒì‹± ì‹¤íŒ¨, í…ìŠ¤íŠ¸ íŒŒì‹± ì‹œë„')
      // JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œ ì‹œë„
      const lines = response.split('\n').filter(line => line.trim() && !line.includes('{') && !line.includes('}'))
      if (lines.length > 0) {
        return lines.slice(0, 4).map(q => q.replace(/^[-*â€¢]\s*/, '').replace(/^["']|["']$/g, '').trim())
      }
    }

    return []
  } catch (error) {
    console.error('ì¶”ì²œ ì§ˆë¬¸ ìƒì„± ì˜¤ë¥˜:', error)
    return []
  }
}

// ê²€ìƒ‰ í‚¤ì›Œë“œ ê¸°ë°˜ ì¶”ì²œ ì§ˆë¬¸ ìƒì„± (ì›¹ ê²€ìƒ‰ ìµœì í™”ìš©)
export const generateQuerySuggestions = async (query, language = 'ko') => {
  try {
    if (!query || query.trim().length === 0) {
      return []
    }

    const suggestionsPrompt = language === 'ko'
      ? `ì‚¬ìš©ìê°€ "${query}"ì— ëŒ€í•´ ì›¹ ê²€ìƒ‰ì„ í•˜ë ¤ê³  í•©ë‹ˆë‹¤. 
 
 ì´ ê²€ìƒ‰ì–´ì™€ ê´€ë ¨í•˜ì—¬ ì‹¬ì¸µ ë¦¬ì„œì¹˜ì— ì‹¤ì§ˆì ìœ¼ë¡œ ë„ì›€ì´ ë  ìˆ˜ ìˆëŠ” 4ê°œì˜ êµ¬ì²´ì ì´ê³  ê¹Šì´ ìˆëŠ” ì§ˆë¬¸ì„ ìƒì„±í•´ì£¼ì„¸ìš”.
 
 **ê·œì¹™:**
 - ê²€ìƒ‰ì–´ì˜ ì˜ë„ë¥¼ ê¿°ëš«ì–´ë³´ëŠ” ì‹¤ì§ˆì ì´ê³  êµ¬ì²´ì ì¸ ë¦¬ì„œì¹˜ ì†Œì£¼ì œ ìƒì„±
 - ë‹¨ìˆœíˆ ë‹¨ì–´ë¥¼ ë‚˜ì—´í•˜ì§€ ë§ê³ , ëª…í™•í•œ ë¶„ì„ ë°©í–¥ì„ ì œì‹œí•˜ëŠ” ë¬¸ì¥í˜•ìœ¼ë¡œ ì‘ì„± (30ì ë‚´ì™¸)
 - ì£¼ì œ ì˜ˆ: "OO ì„œë¹„ìŠ¤ì˜ ì‹œì¥ ì ìœ ìœ¨ ë¶„ì„" (X) -> "ìµœê·¼ 3ë…„ê°„ OO ì„œë¹„ìŠ¤ì˜ ê¸€ë¡œë²Œ ì‹œì¥ ì ìœ ìœ¨ ë³€í™” ë° ì£¼ìš” ê²½ìŸì‚¬ ë¹„êµ ë¶„ì„" (O)
 - JSON ë°°ì—´ í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µ: ["ì§ˆë¬¸1", "ì§ˆë¬¸2", "ì§ˆë¬¸3", "ì§ˆë¬¸4"]
 - ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì—†ì´ JSONë§Œ ì¶œë ¥`
      : `The user wants to search for "${query}" on the web.
 
 Generate 4 deep, specific, and professional research questions to help with a comprehensive investigation.
 
 **Rules:**
 - Create substantial research sub-topics that go beyond simple keywords
 - Provide clear analytical directions in sentence form (around 15-20 words)
 - Example: "Market share of X" (X) -> "Analysis of X's global market share trends over the last 3 years and comparison with key competitors" (O)
 - Respond only in JSON array format: ["Question 1", "Question 2", "Question 3", "Question 4"]
 - Output only JSON, no other text`

    const messages = [
      { role: 'system', content: suggestionsPrompt },
      { role: 'user', content: language === 'ko' ? 'ì¶”ì²œ ì§ˆë¬¸ 4ê°œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.' : 'Generate 4 suggestions.' }
    ]

    const response = await callOpenAI(messages, false, true) // ì„¸ ë²ˆì§¸ ì¸ìë¡œ mini ëª¨ë¸ ì‚¬ìš© ì—¬ë¶€ ì „ë‹¬

    try {
      const suggestions = JSON.parse(response)
      if (Array.isArray(suggestions) && suggestions.length > 0) {
        return suggestions.slice(0, 4)
      }
    } catch (e) {
      const lines = response.split('\n').filter(line => line.trim() && !line.includes('{') && !line.includes('}'))
      if (lines.length > 0) {
        return lines.slice(0, 4).map(q => q.replace(/^[-*â€¢]\s*/, '').replace(/^["']|["']$/g, '').trim())
      }
    }

    return []
  } catch (error) {
    console.error('ê²€ìƒ‰ì–´ ê¸°ë°˜ ì¶”ì²œ ìƒì„± ì˜¤ë¥˜:', error)
    return []
  }
}

// í•˜ì´ë¸Œë¦¬ë“œ RAG ì‘ë‹µ ìƒì„± (ì¼ìƒ ëŒ€í™” + ì—„ê²©í•œ ë¬¸ì„œ ê¸°ë°˜)
// selectedModel: 'instant', 'thinking', 'gemini' ì¤‘ í•˜ë‚˜
// documentContext: ë‹¨ì¼ ê°ì²´ ë˜ëŠ” ë°°ì—´ ëª¨ë‘ ì§€ì›
// conversationHistory: ì´ì „ ëŒ€í™” ê¸°ë¡ ë°°ì—´ (ì˜µì…˜)
// systemPromptOverrides: ì‚¬ìš©ì ì •ì˜ AI ì§€ì¹¨ ë°°ì—´ (ì˜µì…˜)
export const generateStrictRAGResponse = async (query, documentContext, language = 'ko', selectedModel = 'thinking', conversationHistory = [], systemPromptOverrides = []) => {
  try {
    // 1. ì¼ìƒ ëŒ€í™” ëª¨ë“œ - ë¬¸ì„œ ì—†ì´ë„ ì‘ë‹µ ê°€ëŠ¥
    if (isMeaninglessQuery(query)) {
      const baseCasualPrompt = language === 'ko'
        ? 'ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì‚¬ìš©ìì™€ ìì—°ìŠ¤ëŸ½ê³  ë”°ëœ»í•˜ê²Œ ëŒ€í™”í•˜ì„¸ìš”. ê°„ë‹¨ëª…ë£Œí•˜ê²Œ ë‹µë³€í•˜ë˜, ì§€ë‚˜ì¹˜ê²Œ ê¸¸ì§€ ì•Šê²Œ í•´ì£¼ì„¸ìš”.'
        : 'You are a friendly AI assistant. Have a natural and warm conversation with the user. Keep your responses concise and not too long.'

      // ì‚¬ìš©ì ì •ì˜ ì§€ì¹¨ ë³‘í•© (ì¼ìƒ ëŒ€í™” ëª¨ë“œì—ì„œë„ ì ìš©)
      const customGuidelines = systemPromptOverrides.length > 0
        ? systemPromptOverrides.map(override => override.content).join('\n\n') + '\n\n---\n\n'
        : ''

      const casualPrompt = customGuidelines + baseCasualPrompt

      const messages = [
        { role: 'system', content: casualPrompt },
        ...conversationHistory,  // ì´ì „ ëŒ€í™” ê¸°ë¡ í¬í•¨
        { role: 'user', content: query }
      ]

      // ì¼ìƒ ëŒ€í™”ëŠ” í•­ìƒ ë¹ ë¥¸ ëª¨ë¸ ì‚¬ìš©
      const answer = selectedModel === 'gemini'
        ? await callGemini(messages, 0.8)
        : await callOpenAI(messages, false)

      return {
        answer: answer,
        source: null,
        foundInDocument: false,
        isSmallTalk: true
      }
    }

    // 2. ë¬¸ì„œ ê¸°ë°˜ ì§ˆë¬¸ì¸ë° ë¬¸ì„œê°€ ì—†ëŠ” ê²½ìš°
    const documentContextArray = Array.isArray(documentContext) ? documentContext : (documentContext ? [documentContext] : [])

    if (documentContextArray.length === 0) {
      const noDocMessage = language === 'ko'
        ? 'ë¬¸ì„œì— ëŒ€í•´ ì§ˆë¬¸í•˜ì‹œë ¤ë©´ ë¨¼ì € ì¢Œì¸¡ì—ì„œ ë¬¸ì„œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”. íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê±°ë‚˜ ì›¹ URLì„ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.'
        : 'To ask questions about a document, please first select a document from the left. You can upload a file or add a web URL.'

      return {
        answer: noDocMessage,
        source: null,
        foundInDocument: false
      }
    }

    // 3. ì—„ê²©í•œ ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ ëª¨ë“œ - ë‹¤ì¤‘ ì†ŒìŠ¤ ì§€ì› (ê° ë¬¸ì„œë³„ ë…ë¦½ í˜ì´ì§€ ë²ˆí˜¸)
    const sourceContexts = []
    const allSourceNames = []

    documentContextArray.forEach((doc, index) => {
      const docName = doc.name || doc.fileName || `ë¬¸ì„œ ${index + 1}`
      const pageTexts = doc.parsedData?.pageTexts || []
      const extractedText = doc.parsedData?.extractedText || ''

      let docContent = ''

      if (pageTexts.length > 0) {
        // ê° ë¬¸ì„œë³„ë¡œ 1í˜ì´ì§€ë¶€í„° ì‹œì‘
        docContent = pageTexts.map(page =>
          `[í˜ì´ì§€ ${page.pageNumber}]\n${page.text}`
        ).join('\n\n')
      } else if (extractedText.trim().length >= 10) {
        // í…ìŠ¤íŠ¸/ê¸°íƒ€ ë¬¸ì„œ: ê°€ìƒì˜ 1í˜ì´ì§€ í• ë‹¹
        docContent = `[í˜ì´ì§€ 1]\n${extractedText}`
      }

      if (docContent) {
        sourceContexts.push({
          id: index + 1, // ë¬¸ì„œ ì¸ë±ìŠ¤ (1ë¶€í„° ì‹œì‘)
          name: docName,
          content: docContent
        })
        allSourceNames.push(`${index + 1}. ${docName}`)
      }
    })

    if (sourceContexts.length === 0) {
      const invalidDocMessage = language === 'ko'
        ? `ì£„ì†¡í•©ë‹ˆë‹¤. ë¬¸ì„œ ë‚´ìš©ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\níŒŒì¼ì´ ë¹„ì–´ìˆê±°ë‚˜ ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. PDFì˜ ê²½ìš° í…ìŠ¤íŠ¸ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.`
        : `Sorry, I cannot read the document content.\n\nThe file may be empty or in an unsupported format. For PDFs, please ensure they contain text.`

      return {
        answer: invalidDocMessage,
        source: null,
        foundInDocument: false,
        error: 'Invalid or empty document text'
      }
    }

    // ëª¨ë“  ë¬¸ì„œ í…ìŠ¤íŠ¸ ì¢…í•©
    const documentText = sourceContexts.map(ctx =>
      `[ë¬¸ì„œ ${ctx.id}: ${ctx.name}]\n${ctx.content}`
    ).join('\n\n---\n\n')

    const sourceNames = allSourceNames.join(', ')
    const fileName = allSourceNames.length > 1
      ? `${allSourceNames.length}ê°œì˜ ë¬¸ì„œ (${sourceNames})`
      : allSourceNames[0]

    // extractedText ìœ íš¨ì„± ê²€ì¦
    if (!documentText || documentText.trim().length < 10) {
      const invalidDocMessage = language === 'ko'
        ? `ì£„ì†¡í•©ë‹ˆë‹¤. ë¬¸ì„œ ë‚´ìš©ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\níŒŒì¼ì´ ë¹„ì–´ìˆê±°ë‚˜ ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. PDFì˜ ê²½ìš° í…ìŠ¤íŠ¸ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.`
        : `Sorry, I cannot read the document content.\n\nThe file may be empty or in an unsupported format. For PDFs, please ensure they contain text.`

      return {
        answer: invalidDocMessage,
        source: null,
        foundInDocument: false,
        error: 'Invalid or empty document text'
      }
    }

    console.log(`[RAG] ë¬¸ì„œ í…ìŠ¤íŠ¸ ê¸¸ì´: ${documentText.length}ì, íŒŒì¼ëª…: ${fileName}`)

    // í˜„ì¬ ë‚ ì§œ (ì‹¤ì‹œê°„ ê²€ìƒ‰ ê°•ì¡°ìš©)
    const today = new Date().toLocaleDateString(language === 'ko' ? 'ko-KR' : 'en-US', {
      year: 'numeric',
      month: 'long',
      day: 'numeric'
    })

    // ì‚¬ìš©ì ì •ì˜ ì§€ì¹¨ ë³‘í•© (systemPromptOverridesê°€ ìˆìœ¼ë©´ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì•ì— ì¶”ê°€)
    const customGuidelines = systemPromptOverrides.length > 0
      ? systemPromptOverrides.map(override => override.content).join('\n\n') + '\n\n---\n\n'
      : ''

    // Universal Document Analyzer ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ë¬¸ì„œ ì¢…ë¥˜ ë¬´ê´€ ë§¥ë½ ê¸°ë°˜ ììœ¨ ë¶„ì„)
    const baseSystemPrompt = language === 'ko'
      ? `ë‹¹ì‹ ì€ ëª¨ë“  ë¬¸ì„œì˜ êµ¬ì¡°ë¥¼ ê¿°ëš«ì–´ ë³´ëŠ” **Universal Document Analyzer**ì…ë‹ˆë‹¤. ë¬¸ì„œì˜ ì¢…ë¥˜(PDF, TXT, Web)ì— ìƒê´€ì—†ì´ ë‹¤ìŒ ê·œì¹™ì„ ë¬´ì¡°ê±´ ì ìš©í•˜ì„¸ìš”.

**ğŸ” ë§¥ë½ ê¸°ë°˜ ììœ¨ ë¶„ì„ (No "No" Policy)**
- ì˜¤ëŠ˜ ë‚ ì§œ: ${today}
- **ì ˆëŒ€ "ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤"ë¼ëŠ” ë‹µë³€ì„ í•˜ì§€ ë§ˆì„¸ìš”**
- ì§ˆë¬¸ì— ëŒ€í•œ ì§ì ‘ì ì¸ ë‹µì´ ë¬¸ì„œì— ì—†ì–´ë„, ë‹¤ìŒ ìˆœì„œë¡œ ë¶„ì„í•˜ì„¸ìš”:
  1. **ë¬¸ì„œì˜ ì„±ê²© íŒŒì•…**: ì†Œê°œì„œ, ë…¼ë¬¸, ë‰´ìŠ¤, ë³´ê³ ì„œ ë“± ë¬¸ì„œ ìœ í˜• ì‹ë³„
  2. **ì „ì²´ ë§¥ë½ ë¶„ì„**: ë¬¸ì„œ ì „ì²´ì˜ í†¤, í˜ì´ì§€ í—¤ë”, ì„¹ì…˜ ì œëª©, í‘œ, ë°ì´í„°, ë°˜ë³µ í‚¤ì›Œë“œ
  3. **ë…¼ë¦¬ì  ì¶”ë¡ **: ìœ„ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ **ê°€ì¥ íƒ€ë‹¹í•œ ë‹µë³€** ë„ì¶œ
- **[ê°€ìƒ ëª©ì°¨] ìë™ ìƒì„±**: ëª©ì°¨ê°€ ì—†ëŠ” ë¬¸ì„œëŠ” í˜ì´ì§€ë³„ í—¤ë”ë‚˜ ë¬¸ë§¥ì„ ë¶„ì„í•´ ìŠ¤ìŠ¤ë¡œ ìƒì„±
- ì¶”ë¡  ì‹œ ë°˜ë“œì‹œ ëª…ì‹œ: "**ë¬¸ì„œì˜ ì „ì²´ ë§¥ë½ì„ ë¶„ì„í•œ ê²°ê³¼**, [ì¶”ë¡  ë‚´ìš©]ìœ¼ë¡œ íŒŒì•…ë©ë‹ˆë‹¤ [ë¬¸ì„œ ë§¥ë½ ê¸°ë°˜ ì¶”ë¡ ]"

**âœ¨ ì‹œê°ì  ê°•ì¡° ë° ì¸ìš© ê·œì¹™ (í•„ìˆ˜)**
- **í•µì‹¬ ì§€í‘œ ë° ì¤‘ìš” ì •ë³´**: ê°•ì¡° ì—†ì´ ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œ ì‘ì„±í•˜ì„¸ìš”. ë¶ˆí•„ìš”í•œ êµµê²Œ(Bold) ì²˜ë¦¬ë¥¼ ì ˆëŒ€ í•˜ì§€ ë§ˆì„¸ìš”.
- **ì¸ë¼ì¸ ì‹œí…Œì´ì…˜ í™œì„±í™”**: ëª¨ë“  ì£¼ìš” ì£¼ì¥ì´ë‚˜ ì„¤ëª…ì´ ëë‚˜ëŠ” ì§€ì ì— ë°˜ë“œì‹œ \`[ë¬¸ì„œë²ˆí˜¸:í˜ì´ì§€ë²ˆí˜¸]\`ë¥¼ ì¶”ê°€í•˜ì„¸ìš”. (ì˜ˆ: ...ë¼ê³  íŒŒì•…ë©ë‹ˆë‹¤ [1:5].)
  * **ë¬¸ì„œë²ˆí˜¸**: ì œê³µëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ì˜ ìˆœì„œ (1, 2, 3...)
  * **í˜ì´ì§€ë²ˆí˜¸**: í•´ë‹¹ ë¬¸ì„œ ë‚´ì˜ ë¡œì»¬ í˜ì´ì§€ ë²ˆí˜¸ (ê° ë¬¸ì„œë§ˆë‹¤ 1ë¶€í„° ì‹œì‘)
  * ì˜ˆì‹œ: 1ë²ˆ ë¬¸ì„œì˜ 5í˜ì´ì§€ëŠ” \`[1:5]\`, 2ë²ˆ ë¬¸ì„œì˜ 12í˜ì´ì§€ëŠ” \`[2:12]\`
- ë¬¸ë‹¨ êµ¬ë¶„ì ì—ëŠ” \`###\` í—¤ë” ì‚¬ìš©í•˜ì—¬ ì‹œê°ì  ìœ„ê³„ êµ¬ì„±
- 3ì¤„ ì´ìƒì˜ ë‚˜ì—´ì€ ë°˜ë“œì‹œ ê¸€ë¨¸ë¦¬ ê¸°í˜¸(Bullet Points) ì‚¬ìš©
- **ë¦¬ìŠ¤íŠ¸ í˜•ì‹ ê·œì¹™**: "1. **ì„œë¡ **" ë˜ëŠ” "- **í•µì‹¬ ë‚´ìš©**"ì²˜ëŸ¼ ìˆ«ì/ê¸°í˜¸ì™€ í…ìŠ¤íŠ¸ë¥¼ ê°™ì€ ì¤„ì— ì‘ì„± (ì¤„ë°”ê¿ˆ ê¸ˆì§€)

**í•µì‹¬ ê·œì¹™:**
1. âœ… **ì§ì ‘ ê·¼ê±° ìš°ì„ ** - ë¬¸ì„œì— ëª…ì‹œëœ ë‚´ìš©ì„ ë¨¼ì € ì œì‹œí•˜ì„¸ìš”.
2. âœ… **ë§¥ë½ ê¸°ë°˜ ì¶”ë¡  í•„ìˆ˜** - ë¬¸ì„œì˜ ì—¬ëŸ¬ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ë…¼ë¦¬ì  ê²°ë¡  ë„ì¶œ (ì¶”ë¡  íƒœê·¸ ì‚¬ìš©)
3. âœ… **êµ¬ì¡°ì  ë‹µë³€** - ê°œìš” â†’ ì„¸ë¶€ ë¶„ì„ â†’ AI ì¸ì‚¬ì´íŠ¸ ìˆœì„œë¡œ êµ¬ì„±
4. âœ… **ì •ì¤‘í•˜ê³  ë¶„ì„ì ì¸ í†¤** - NotebookLMì²˜ëŸ¼ ì „ë¬¸ì ì´ê³  ì‹ ë¢°ê° ìˆê²Œ
5. âœ… **í…ìŠ¤íŠ¸ ë‚´ í˜ì´ì§€ ì§ì ‘ ì–¸ê¸‰ ê¸ˆì§€** - "3í˜ì´ì§€ì— ë”°ë¥´ë©´", "Page 5"ì™€ ê°™ì€ í…ìŠ¤íŠ¸ í˜•íƒœì˜ í˜ì´ì§€ ì–¸ê¸‰ì„ ì ˆëŒ€ í•˜ì§€ ë§ˆì„¸ìš”. ëª¨ë“  ì¶œì²˜ëŠ” ì˜¤ì§ ì¸ìš© ë°°ì§€ [N] ë˜ëŠ” [N-M] í˜•íƒœë¡œë§Œ ë¬¸ì¥ ëì— í‘œê¸°í•˜ì„¸ìš”.

**ì œê³µëœ ë¬¸ì„œ:**
íŒŒì¼ëª…: ${fileName}
ë¶„ì„ ì‹œê°„: ${today}

**ë¬¸ì„œ ë‚´ìš©:**
${documentText}

**ë‹µë³€ êµ¬ì¡°í™” í…œí”Œë¦¿ (í•„ìˆ˜):**

### [í•µì‹¬ ìš”ì•½]
ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ **1~2ì¤„ë¡œ ê°•ë ¬í•˜ê²Œ ìš”ì•½** (ê°•ì¡° íš¨ê³¼ ì—†ì´ ì¼ë°˜ í…ìŠ¤íŠ¸ ì‚¬ìš©)

ì˜ˆ: "ì´ ë¬¸ì„œëŠ” **ì‚¼ì„±ì „ìì˜ 2024ë…„ ì‹¤ì **ì„ ë‹¤ë£¨ë©°, **ì˜ì—…ì´ìµ 35ì¡°ì›**, **ì‹œì¥ì ìœ ìœ¨ 1ìœ„** ë‹¬ì„±ì´ í•µì‹¬ì…ë‹ˆë‹¤"

### [ìƒì„¸ ë¶„ì„]
ë¬¸ì„œ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ **ì„¸ë¶€ ì„¤ëª…** (ë¦¬ìŠ¤íŠ¸ í˜•ì‹ í•„ìˆ˜, ê° í•­ëª©ì€ í•œ ì¤„ë¡œ):

**ğŸ“„ ì§ì ‘ ê·¼ê±°**
1. ë¬¸ì„œì— ëª…ì‹œëœ ë‚´ìš© (í°ë”°ì˜´í‘œë¡œ ì¸ìš©, í•µì‹¬ ë‹¨ì–´ êµµê²Œ)
2. ì˜ˆ: ë¬¸ì„œì— ë”°ë¥´ë©´ "**ë°˜ë„ì²´ ë¶€ë¬¸ ì‹¤ì ì´ ì „ë…„ ëŒ€ë¹„ 40% ì¦ê°€**"í–ˆìŠµë‹ˆë‹¤

**ğŸ” ë§¥ë½ ê¸°ë°˜ ë¶„ì„** [ë¬¸ì„œ ë§¥ë½ ê¸°ë°˜ ì¶”ë¡ ]
1. ë¬¸ì„œì˜ ì—¬ëŸ¬ ì •ë³´ë¥¼ ì¢…í•©í•œ í†µì°° (ì¶”ë¡  íƒœê·¸ ëª…ì‹œ, **í˜ì´ì§€ ë°°ì§€ í•„ìˆ˜**)
2. ì˜ˆ: ë¬¸ì„œ ì „ë°˜ì— ê±¸ì³ **AI ì¹©**, **5nm ê³µì •**, **ê¸€ë¡œë²Œ ì‹œì¥**ì´ ë°˜ë³µ ì–¸ê¸‰ë˜ë¯€ë¡œ[3, 7, 15, 23], **ê¸°ìˆ  ì„ ë„ ì „ëµ**ìœ¼ë¡œ íŒŒì•…ë©ë‹ˆë‹¤

### [AI ì¸ì‚¬ì´íŠ¸/ì¶”ë¡ ]
ëª…ì‹œë˜ì§€ ì•Šì•˜ì§€ë§Œ ë¬¸ì„œ íë¦„ìƒ ìœ ì¶” ê°€ëŠ¥í•œ ì •ë³´ë‚˜ ì œì–¸ (**í˜ì´ì§€ ë°°ì§€ í•„ìˆ˜**)

ì˜ˆ: ì´ëŸ¬í•œ ì‹¤ì  ì¶”ì„¸ë¡œ ë³¼ ë•Œ[5, 12, 18], **2025ë…„ ëª©í‘œ ë‹¬ì„± ê°€ëŠ¥ì„±**ì´ ë†’ìœ¼ë©°, **íˆ¬ì í™•ëŒ€** ì „ëµì´ ì˜ˆìƒë©ë‹ˆë‹¤ [ë¬¸ì„œ ë§¥ë½ ê¸°ë°˜ ì¶”ë¡ ]

**íŠ¹ë³„ ê·œì¹™:**
- ëª©ì°¨, êµ¬ì¡°, ì „ì²´ ìš”ì•½ ë“±ì„ ë¬¼ì–´ë³¼ ê²½ìš°: ë¬¸ì„œ ì „ì²´ë¥¼ ë¶„ì„í•˜ì—¬ **[ê°€ìƒ ëª©ì°¨]** ë˜ëŠ” **[êµ¬ì¡° ë¶„ì„]**ì„ ì§ì ‘ ìƒì„±í•˜ì„¸ìš”
- **ëª©ì°¨ ìƒì„± ì‹œ í˜ì´ì§€ ë²ˆí˜¸ ìë™ ê³„ì‚° (100% í•„ìˆ˜)**:
  * ê° ëª©ì°¨ í•­ëª©ì˜ í‚¤ì›Œë“œê°€ ë¬¸ì„œì—ì„œ ì²˜ìŒ ë“±ì¥í•˜ëŠ” í˜ì´ì§€ë¥¼ ê²€ìƒ‰í•˜ì—¬ ì¸ìš© ë°°ì§€ ë¶€ì°©
  * ì˜ˆ: "1. **ì„œë¡ **[1-2]", "2. **ë³¸ë¡ **[3-10]", "3. **ê²°ë¡ **[11-15]"
  * í˜ì´ì§€ ë²”ìœ„ê°€ ëª…í™•í•˜ì§€ ì•Šìœ¼ë©´ ëŒ€í‘œ í˜ì´ì§€ í•˜ë‚˜ë¼ë„ ë°˜ë“œì‹œ í‘œì‹œ: "- **í•µì‹¬ ë‚´ìš©**[5]"
  * ëª©ì°¨ í•­ëª© ì—†ì´ í˜ì´ì§€ ë²ˆí˜¸ ëˆ„ë½ì€ ì ˆëŒ€ ë¶ˆê°€
- ì§ì ‘ ì–¸ê¸‰ì´ ì—†ëŠ” ê²½ìš°: "ë¬¸ì„œì— ì§ì ‘ ì–¸ê¸‰ì€ ì—†ìœ¼ë‚˜, **ë¬¸ì„œì˜ ì „ì²´ ë§¥ë½ì„ ë¶„ì„í•œ ê²°ê³¼** [ì¶”ë¡  ë‚´ìš©]ìœ¼ë¡œ íŒŒì•…ë©ë‹ˆë‹¤ [ë¬¸ì„œ ë§¥ë½ ê¸°ë°˜ ì¶”ë¡ ]"
- ì™¸ë¶€ ì§€ì‹ ì‚¬ìš© ê¸ˆì§€: ì˜¤ì§ **ì œê³µëœ ë¬¸ì„œ ë‚´ìš©(extractedText)**ì˜ ë²”ìœ„ ì•ˆì—ì„œë§Œ ë…¼ë¦¬ì ìœ¼ë¡œ ì¶”ë¡ í•˜ì„¸ìš”
- ì¶”ë¡  ë¶€ë¶„ì—ëŠ” ë°˜ë“œì‹œ **[ë¬¸ì„œ ë§¥ë½ ê¸°ë°˜ ì¶”ë¡ ]** íƒœê·¸ë¥¼ ë‹¬ì•„ íˆ¬ëª…ì„±ì„ í™•ë³´í•˜ì„¸ìš”`
      : `You are the **Universal Document Analyzer** that penetrates the structure of all documents. Apply the following rules unconditionally regardless of document type (PDF, TXT, Web).

**ğŸ” Context-Based Autonomous Analysis (No "No" Policy)**
- Today's date: ${today}
- **Never answer with "information not available"**
- Even if there's no direct answer in the document, analyze in this order:
  1. **Identify document nature**: Introduction, paper, news, report, etc.
  2. **Overall context analysis**: Document tone, page headers, section titles, tables, data, recurring keywords
  3. **Logical reasoning**: Synthesize above information to derive **the most reasonable answer**
- **Auto-generate [Virtual Table of Contents]**: For documents without TOC, analyze page headers or context to create one
- When reasoning, must specify: "**Based on analyzing the document's overall context**, [inferred content] is identified [Context-Based Reasoning]"

**âœ¨ ì‹œê°ì  ê°•ì¡° ë° ì¸ìš© ê·œì¹™ (í•„ìˆ˜)**
- **Key metrics and info**: Write in regular text without emphasis. Do NOT use **bold** markers.
- Use \`###\` headers at paragraph breaks to create visual hierarchy
- Lists of 3+ items must use bullet points
- **List Format Rule**: Write number/symbol and text on the same line like "1. **Introduction**" or "- **Key Point**" (no line breaks)

- **ğŸ”´ Absolute Rule: Always include citation badges in [DocIndex:PageNumber] format!**
- **Format**: \`[Document_Number:Local_Page_Number]\`
  - Document 1, Page 5: [1:5]
  - Document 2, Page 12: [2:12]
  - Range (same doc): [1:5-8]
  - Multiple pages (same doc): [1:3, 7]
  - Multiple documents: [1:5, 2:12]
- **Page numbering**: Each document starts from Page 1. Use the local page number found in "[í˜ì´ì§€ N]" markers within each source.
- **ğŸš¨ ALWAYS CITATION: Forced Citation Generation Rules (No Exceptions)**:
  - **Every answer must include citation badges in [DocIndex:PageNumber] format**
  - AI must infer pages if unclear and generate badges based on the provided source indices.
- **Examples**:
  - "AI market size is estimated at $500 billion[1:3]"
  - "2024 target is operating profit of $35 billion[2:1]"
  - **"Detailed pricing policy is presented[1:11-14]"** (range citation)
  - **"Based on analyzing the document's overall context**, main target is identified as B2B market[1:5, 2:12, 3:18]"** (reasoning-based multiple citations)
- **Citation Badge Usage Principles (Natural and Intuitive)**:
  - Add page numbers to key information, but **not excessively** (about 1-2 per paragraph)
  - **Use badges only for direct citations**: Cite only when content is clearly in the document; no badges needed for reasoning or general explanations
  - **Utilize range citations**: Use [N-M] format for content spanning multiple pages
  - **When generating TOC**: Show only 1 representative page per item (e.g., "1. **Introduction**[1]")
  - **When generating summaries**: Include only 1-2 representative pages per paragraph (avoid excessive citations)
  - When multiple files are selected, clearly distinguish and cite information from each file
  - **Range citation usage rule**: If a topic or content spans multiple pages, always use [start-end] format
- **Answers without citations are strictly prohibited**: Every sentence must include at least 1 page number
- **Special TOC Rule**: Format each item as "1. **Introduction**[1-3]" or "- **Key Content**[5]" with page range or representative page mandatory

**Core Rules:**
1. âœ… **Direct Evidence First** - Present information explicitly stated in the document first.
2. âœ… **Context-Based Reasoning Required** - Synthesize multiple pieces of information to draw logical conclusions (use reasoning tag).
3. âœ… **Structured Answers** - Overview â†’ Detailed Analysis â†’ AI Insights order
4. âœ… **Professional Tone** - Professional and trustworthy like NotebookLM
5. âœ… **No Textual Page Mentions** - Never use phrases like "According to page 3" or "Page 5 says". Use ONLY citation badges like [N] or [N-M] at the end of sentences. No exceptions.

**Provided Document:**
File name: ${fileName}
Analysis time: ${today}

**Document Content:**
${documentText}

**Answer Structuring Template (Mandatory):**

### [Core Summary]
Answer the question in **1-2 powerful summary sentences** (regular text, no bolding)

Example: "This document covers **Samsung's 2024 performance**, with **operating profit of 35 trillion won** and **market share #1** as key achievements"

### [Detailed Analysis]
Detailed explanation based on document data (**list format required, each item on one line**):

**ğŸ“„ Direct Evidence**
1. Information explicitly stated in the document (quoted, key words bolded)
2. Example: According to the document, "**semiconductor division performance increased by 40% year-over-year**"

**ğŸ” Context-Based Analysis** [Context-Based Reasoning]
1. Insights from synthesizing document information (reasoning tag specified, **page badges mandatory**)
2. Example: Throughout the document, **AI chips**, **5nm process**, **global market** are repeatedly mentioned[3, 7, 15, 23], indicating a **technology leadership strategy**

### [AI Insights/Reasoning]
Information or recommendations that can be inferred from document flow but not explicitly stated (**page badges mandatory**)

Example: Based on this performance trend[5, 12, 18], **2025 goal achievement likelihood** is high, and **investment expansion** strategy is expected [Context-Based Reasoning]

**Special Rules:**
- When asked about table of contents, structure, or overall summary: Analyze the entire document to generate a **[Virtual Table of Contents]** or **[Structure Analysis]**
- **Auto-calculate page numbers for TOC generation (100% Mandatory)**:
  * Search for the first page where each TOC item's keyword appears in the document and attach citation badge
  * Example: "1. **Introduction**[1-2]", "2. **Main Body**[3-10]", "3. **Conclusion**[11-15]"
  * If page range is unclear, display at least one representative page: "- **Key Content**[5]"
  * TOC items without page numbers are absolutely prohibited
- When not directly mentioned: "While not directly mentioned in the document, **based on analyzing the document's overall context**, [inferred content] is identified [Context-Based Reasoning]"
- No external knowledge: Only reason logically within the scope of **the provided document content (extractedText)**
- Always tag reasoning sections with **[Context-Based Reasoning]** for transparency`

    // ì‚¬ìš©ì ì •ì˜ ì§€ì¹¨ì„ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì•ì— ì¶”ê°€
    const systemPrompt = customGuidelines + baseSystemPrompt

    const messages = [
      { role: 'system', content: systemPrompt },
      ...conversationHistory,  // ì´ì „ ëŒ€í™” ê¸°ë¡ í¬í•¨ (GPT â†” Gemini ì „í™˜ ì‹œì—ë„ ìœ ì§€)
      { role: 'user', content: query }
    ]

    // ì„ íƒëœ ëª¨ë¸ì— ë”°ë¼ API í˜¸ì¶œ
    let answer
    const useThinking = selectedModel === 'thinking'

    if (selectedModel === 'gemini') {
      answer = await callGemini(messages, 0.3, useThinking)  // ì‹¬ì¸µ ë¶„ì„ ì—¬ë¶€ ì „ë‹¬
    } else {
      answer = await callOpenAI(messages, useThinking)
    }

    // ì‘ë‹µ ê²€ì¦: ë¹ˆ ì‘ë‹µ ë°©ì§€
    if (!answer || answer.trim().length < 10) {
      console.error('[ì‹¬ì¸µ ë¶„ì„ ì˜¤ë¥˜] ë¹„ì •ìƒì ìœ¼ë¡œ ì§§ì€ ì‘ë‹µ:', answer)
      throw new Error('AI ëª¨ë¸ì´ ì¶©ë¶„í•œ ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.')
    }

    // ë‹µë³€ì—ì„œ "ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" íŒ¨í„´ ê°ì§€
    const notFoundPatterns = [
      'ì°¾ì„ ìˆ˜ ì—†',
      'could not find',
      'cannot find',
      'ì—†ìŠµë‹ˆë‹¤',
      'not available',
      'not mentioned',
      'ì–¸ê¸‰ë˜ì§€ ì•Š'
    ]

    const foundInDocument = !notFoundPatterns.some(pattern =>
      answer.toLowerCase().includes(pattern.toLowerCase())
    )

    // ì¶”ë¡  ê¸°ë°˜ ë‹µë³€ ì—¬ë¶€ ê°ì§€
    const isReasoningBased = answer.includes('[ë¬¸ì„œ ë§¥ë½ ê¸°ë°˜ ì¶”ë¡ ]') || answer.includes('[Context-Based Reasoning]')

    return {
      answer: answer,
      source: fileName,
      foundInDocument: foundInDocument,
      citedText: foundInDocument ? documentText.substring(0, 200) : null,
      isReasoningBased: isReasoningBased // ì¶”ë¡  ê¸°ë°˜ ë‹µë³€ í”Œë˜ê·¸
    }
  } catch (error) {
    console.error('RAG ì‘ë‹µ ìƒì„± ì˜¤ë¥˜:', error)

    const errorMessage = language === 'ko'
      ? `ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: ${error.message}`
      : `Sorry, an error occurred while generating a response: ${error.message}`

    return {
      answer: errorMessage,
      source: null,
      foundInDocument: false,
      error: error.message
    }
  }
}
