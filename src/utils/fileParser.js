import * as pdfjsLib from 'pdfjs-dist'
import mammoth from 'mammoth'
import * as XLSX from 'xlsx'

// PDF.js worker ì„¤ì • - ë¡œì»¬ ì›Œì»¤ ì‚¬ìš©
pdfjsLib.GlobalWorkerOptions.workerSrc = new URL(
  'pdfjs-dist/build/pdf.worker.min.mjs',
  import.meta.url
).toString()

// PDF í˜ì´ì§€ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜ (ì¸ë„¤ì¼ìš© - íšŒì „ ì •ë³´ ì •ê·œí™” + ê³ í•´ìƒë„)
const renderPDFPageToImage = async (page, scale = 0.6) => {
  try {
    // PDF í˜ì´ì§€ì˜ íšŒì „ ì •ë³´ë¥¼ ë¬´ì‹œí•˜ê³  í•­ìƒ 0ë„ë¡œ ê³ ì • (ì •ë°©í–¥)
    const viewport = page.getViewport({ scale, rotation: 0 })
    const canvas = document.createElement('canvas')
    const context = canvas.getContext('2d')

    // ê³ í•´ìƒë„ ë Œë”ë§ì„ ìœ„í•œ í”½ì…€ ë°€ë„ ì¡°ì • (3.0ë°°ë¡œ ë§¤ìš° ì„ ëª…í•˜ê²Œ)
    const outputScale = 3.0
    canvas.width = Math.floor(viewport.width * outputScale)
    canvas.height = Math.floor(viewport.height * outputScale)

    // ì»¨í…ìŠ¤íŠ¸ ì´ˆê¸°í™” ë° ë°°ê²½ í°ìƒ‰ìœ¼ë¡œ ì„¤ì •
    context.fillStyle = 'white'
    context.fillRect(0, 0, canvas.width, canvas.height)

    // Identity Matrixë¡œ ì¢Œí‘œê³„ ì™„ì „ ë¦¬ì…‹ (ë°˜ì „ ë°©ì§€ - ì „ì—­ ì ìš©)
    context.setTransform(outputScale, 0, 0, outputScale, 0, 0)

    await page.render({
      canvasContext: context,
      viewport: viewport
    }).promise

    // Canvasë¥¼ Base64 ì´ë¯¸ì§€ë¡œ ë³€í™˜ (ìµœê³  í’ˆì§ˆ)
    return canvas.toDataURL('image/png', 1.0)
  } catch (error) {
    console.error('[PDF ì´ë¯¸ì§€ ë³€í™˜] ì˜¤ë¥˜:', error)
    return null
  }
}

// Word íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
const extractWordText = async (file) => {
  try {
    console.log('[Word ì¶”ì¶œ] ì‹œì‘:', file.name, 'Size:', file.size)
    const arrayBuffer = await file.arrayBuffer()
    const result = await mammoth.extractRawText({ arrayBuffer })
    const text = result.value

    // Word íŒŒì¼ì„ í˜ì´ì§€ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ê¸° (500ë‹¨ì–´ë‹¹ 1í˜ì´ì§€ë¡œ ê°€ì •)
    const wordsPerPage = 500
    const words = text.split(/\s+/)
    const totalPages = Math.max(1, Math.ceil(words.length / wordsPerPage))
    const pageTexts = []

    for (let i = 0; i < totalPages; i++) {
      const startIdx = i * wordsPerPage
      const endIdx = Math.min((i + 1) * wordsPerPage, words.length)
      const pageContent = words.slice(startIdx, endIdx).join(' ')

      pageTexts.push({
        pageNumber: i + 1,
        text: pageContent,
        wordCount: endIdx - startIdx,
        thumbnail: null // Word íŒŒì¼ì€ ì¸ë„¤ì¼ ì—†ìŒ
      })
    }

    console.log('[Word ì¶”ì¶œ] ì™„ë£Œ - ì´ ê¸¸ì´:', text.length, 'í˜ì´ì§€:', totalPages)

    return {
      text: text,
      pageCount: totalPages,
      pageTexts: pageTexts,
      pageImages: []
    }
  } catch (error) {
    console.error('[Word ì¶”ì¶œ] ì˜¤ë¥˜:', error)
    throw new Error('Word íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
  }
}

// Excel íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
const extractExcelText = async (file) => {
  try {
    console.log('[Excel ì¶”ì¶œ] ì‹œì‘:', file.name, 'Size:', file.size)
    const arrayBuffer = await file.arrayBuffer()
    const workbook = XLSX.read(arrayBuffer, { type: 'array' })

    let fullText = ''
    const sheets = {}
    const pageTexts = []
    let pageNumber = 1

    workbook.SheetNames.forEach((sheetName) => {
      const worksheet = workbook.Sheets[sheetName]
      const jsonData = XLSX.utils.sheet_to_json(worksheet, { header: 1, defval: '' })

      // ì‹œíŠ¸ ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
      let sheetText = `[ì‹œíŠ¸: ${sheetName}]\n\n`

      jsonData.forEach((row, rowIndex) => {
        if (row.some(cell => cell !== '')) { // ë¹ˆ í–‰ ì œì™¸
          const rowText = row.map((cell, colIndex) => {
            return cell !== '' ? `${cell}` : ''
          }).filter(cell => cell !== '').join(' | ')

          if (rowText) {
            sheetText += rowText + '\n'
          }
        }
      })

      fullText += sheetText + '\n\n'

      // ì‹œíŠ¸ë³„ í˜ì´ì§€ ìƒì„± (ê° ì‹œíŠ¸ë¥¼ ë³„ë„ í˜ì´ì§€ë¡œ)
      pageTexts.push({
        pageNumber: pageNumber++,
        text: sheetText,
        wordCount: sheetText.split(/\s+/).length,
        thumbnail: null,
        sheetName: sheetName
      })

      sheets[sheetName] = {
        name: sheetName,
        data: jsonData,
        rowCount: jsonData.length,
        columnCount: jsonData[0]?.length || 0
      }
    })

    console.log('[Excel ì¶”ì¶œ] ì™„ë£Œ - ì´ ì‹œíŠ¸:', workbook.SheetNames.length)

    return {
      text: fullText,
      pageCount: workbook.SheetNames.length,
      pageTexts: pageTexts,
      pageImages: [],
      sheets: sheets,
      sheetNames: workbook.SheetNames
    }
  } catch (error) {
    console.error('[Excel ì¶”ì¶œ] ì˜¤ë¥˜:', error)
    throw new Error('Excel íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
  }
}

// PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (í˜ì´ì§€ë³„ ë©”íƒ€ë°ì´í„° + ì´ë¯¸ì§€ í¬í•¨)
const extractPDFText = async (file) => {
  try {
    console.log('[PDF ì¶”ì¶œ] ì‹œì‘:', file.name, 'Size:', file.size)
    const arrayBuffer = await file.arrayBuffer()
    const pdf = await pdfjsLib.getDocument({ data: arrayBuffer }).promise
    let fullText = ''
    const pageTexts = [] // í˜ì´ì§€ë³„ í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€ ì €ì¥
    const pageImages = [] // í˜ì´ì§€ë³„ ì¸ë„¤ì¼ ì´ë¯¸ì§€

    console.log('[PDF ì¶”ì¶œ] PDF ë¡œë“œ ì„±ê³µ, ì´ í˜ì´ì§€:', pdf.numPages)

    for (let i = 1; i <= pdf.numPages; i++) {
      const page = await pdf.getPage(i)
      const textContent = await page.getTextContent()

      // ë””ë²„ê¹…: ì²« ë²ˆì§¸ í˜ì´ì§€ì˜ ì²« 5ê°œ ì•„ì´í…œ ì¶œë ¥
      if (i === 1) {
        console.log('[PDF ì¶”ì¶œ] ì²« í˜ì´ì§€ í…ìŠ¤íŠ¸ ì•„ì´í…œ ìƒ˜í”Œ:',
          textContent.items.slice(0, 5).map(item => ({
            str: item.str,
            length: item.str.length,
            charCodes: Array.from(item.str).map(c => c.charCodeAt(0))
          }))
        )
      }

      // ê° í…ìŠ¤íŠ¸ ì•„ì´í…œì„ ê³µë°±ìœ¼ë¡œ ì—°ê²°
      const pageText = textContent.items
        .map(item => item.str)
        .filter(str => str.trim().length > 0) // ë¹ˆ ë¬¸ìì—´ ì œê±°
        .join(' ')

      // ğŸ”¥ ì„ì‹œ: IndexedDB ì €ì¥ì„ ìœ„í•´ ì¸ë„¤ì¼ ë¹„í™œì„±í™” (Base64 ì´ë¯¸ì§€ê°€ ë„ˆë¬´ í¼)
      // const thumbnail = await renderPDFPageToImage(page, 0.6)
      const thumbnail = null // ì¸ë„¤ì¼ ë¹„í™œì„±í™”

      // í˜ì´ì§€ë³„ ë°ì´í„° ì €ì¥
      pageTexts.push({
        pageNumber: i,
        text: pageText,
        wordCount: pageText.split(/\s+/).length,
        thumbnail: thumbnail // nullë¡œ ì €ì¥
      })

      pageImages.push({
        pageNumber: i,
        thumbnail: thumbnail
      })

      fullText += pageText + '\n\n'

      if (i === 1) {
        console.log('[PDF ì¶”ì¶œ] ì²« í˜ì´ì§€ ì¶”ì¶œ ê²°ê³¼ (ì²« 200ì):', pageText.substring(0, 200))
        console.log('[PDF ì¶”ì¶œ] ì¸ë„¤ì¼ ìƒì„±:', thumbnail ? 'ì„±ê³µ' : 'ì‹¤íŒ¨')
      }
    }

    const finalText = fullText.trim()
    console.log('[PDF ì¶”ì¶œ] ì™„ë£Œ - ì´ ê¸¸ì´:', finalText.length, 'ì¸ë„¤ì¼ ê°œìˆ˜:', pageImages.length)

    return {
      text: finalText,
      pageCount: pdf.numPages,
      pageTexts: pageTexts, // í˜ì´ì§€ë³„ í…ìŠ¤íŠ¸ + ì¸ë„¤ì¼ ë°°ì—´
      pageImages: pageImages // í˜ì´ì§€ë³„ ì¸ë„¤ì¼ë§Œ ë³„ë„ ì €ì¥
    }
  } catch (error) {
    console.error('[PDF ì¶”ì¶œ] ì˜¤ë¥˜:', error)
    throw new Error('PDF íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
  }
}

// íŒŒì¼ ë‚´ìš©ì„ íŒŒì‹±í•˜ì—¬ êµ¬ì¡°í™”ëœ JSONìœ¼ë¡œ ë³€í™˜
export const parseFileContent = async (file) => {
  return new Promise(async (resolve, reject) => {
    try {
      let parsedData = {}

      if (file.type === 'application/json') {
        // JSON íŒŒì¼ì¸ ê²½ìš°
        const reader = new FileReader()
        reader.onload = (e) => {
          try {
            parsedData = JSON.parse(e.target.result)
            resolve(parsedData)
          } catch (error) {
            reject(new Error('JSON íŒŒì¼ íŒŒì‹± ì‹¤íŒ¨'))
          }
        }
        reader.onerror = () => reject(new Error('íŒŒì¼ ì½ê¸° ì‹¤íŒ¨'))
        reader.readAsText(file)
      } else if (file.type === 'text/plain' || file.name.endsWith('.txt')) {
        // TXT íŒŒì¼ì¸ ê²½ìš° - ì‹¤ì œ ë‚´ìš© ì½ê¸° + í˜ì´ì§€ êµ¬ì¡° ì¶”ê°€
        const reader = new FileReader()
        reader.onload = (e) => {
          const content = e.target.result
          const lines = content.split('\n').filter(line => line.trim())

          // TXT íŒŒì¼ì„ í˜ì´ì§€ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ê¸° (500ë‹¨ì–´ë‹¹ 1í˜ì´ì§€ë¡œ ê°€ì •)
          const wordsPerPage = 500
          const words = content.split(/\s+/)
          const totalPages = Math.max(1, Math.ceil(words.length / wordsPerPage))
          const pageTexts = []

          for (let i = 0; i < totalPages; i++) {
            const startIdx = i * wordsPerPage
            const endIdx = Math.min((i + 1) * wordsPerPage, words.length)
            const pageContent = words.slice(startIdx, endIdx).join(' ')

            pageTexts.push({
              pageNumber: i + 1,
              text: pageContent,
              wordCount: endIdx - startIdx,
              thumbnail: null // TXT íŒŒì¼ì€ ì¸ë„¤ì¼ ì—†ìŒ
            })
          }

          parsedData = {
            fileType: 'text',
            fileName: file.name,
            fileSize: file.size,
            encoding: 'utf-8',
            totalLines: lines.length,
            pageCount: totalPages,
            content: content,
            lines: lines,
            extractedText: content, // ì‹¤ì œ íŒŒì¼ ë‚´ìš©
            pageTexts: pageTexts, // í˜ì´ì§€ë³„ í…ìŠ¤íŠ¸ êµ¬ì¡° ì¶”ê°€
            metadata: {
              paragraphs: content.split('\n\n').filter(p => p.trim()).length,
              words: content.split(/\s+/).length,
              characters: content.length
            }
          }
          resolve(parsedData)
        }
        reader.onerror = () => reject(new Error('íŒŒì¼ ì½ê¸° ì‹¤íŒ¨'))
        reader.readAsText(file)
      } else if (file.type.includes('pdf') || file.name.endsWith('.pdf')) {
        // PDF íŒŒì¼ - ì‹¤ì œ ë‚´ìš© ì¶”ì¶œ
        console.log('[íŒŒì¼ íŒŒì‹±] PDF íŒŒì¼ ê°ì§€:', file.name)
        const pdfData = await extractPDFText(file)

        console.log('[íŒŒì¼ íŒŒì‹±] PDF ì¶”ì¶œ ì™„ë£Œ - í…ìŠ¤íŠ¸ ê¸¸ì´:', pdfData.text.length)
        console.log('[íŒŒì¼ íŒŒì‹±] extractedText ì²« 300ì:', pdfData.text.substring(0, 300))

        parsedData = {
          fileType: 'pdf',
          fileName: file.name,
          fileSize: file.size,
          content: pdfData.text.substring(0, 500) + '...', // ë¯¸ë¦¬ë³´ê¸°ìš©
          extractedText: pdfData.text, // ì‹¤ì œ ì „ì²´ ë‚´ìš©
          pageTexts: pdfData.pageTexts, // í˜ì´ì§€ë³„ í…ìŠ¤íŠ¸ + ì¸ë„¤ì¼ ë°°ì—´
          pageImages: pdfData.pageImages, // í˜ì´ì§€ë³„ ì¸ë„¤ì¼ë§Œ ë³„ë„ ì €ì¥
          pageCount: pdfData.pageCount, // ì „ì²´ í˜ì´ì§€ ìˆ˜
          metadata: {
            pages: pdfData.pageCount,
            author: 'Unknown',
            createdDate: new Date().toISOString()
          }
        }

        console.log('[íŒŒì¼ íŒŒì‹±] parsedData ìƒì„± ì™„ë£Œ:', {
          fileType: parsedData.fileType,
          fileName: parsedData.fileName,
          extractedTextLength: parsedData.extractedText.length,
          pageTextsCount: parsedData.pageTexts.length,
          pageImagesCount: parsedData.pageImages?.length || 0,
          extractedTextPreview: parsedData.extractedText.substring(0, 100)
        })

        resolve(parsedData)
      } else if (file.type.includes('word') || file.name.endsWith('.docx') || file.name.endsWith('.doc')) {
        // Word íŒŒì¼ - ì‹¤ì œ ë‚´ìš© ì¶”ì¶œ
        console.log('[íŒŒì¼ íŒŒì‹±] Word íŒŒì¼ ê°ì§€:', file.name)
        const wordData = await extractWordText(file)

        console.log('[íŒŒì¼ íŒŒì‹±] Word ì¶”ì¶œ ì™„ë£Œ - í…ìŠ¤íŠ¸ ê¸¸ì´:', wordData.text.length)

        parsedData = {
          fileType: 'word',
          fileName: file.name,
          fileSize: file.size,
          content: wordData.text.substring(0, 500) + '...', // ë¯¸ë¦¬ë³´ê¸°ìš©
          extractedText: wordData.text, // ì‹¤ì œ ì „ì²´ ë‚´ìš©
          pageTexts: wordData.pageTexts, // í˜ì´ì§€ë³„ í…ìŠ¤íŠ¸
          pageImages: wordData.pageImages,
          pageCount: wordData.pageCount, // ì „ì²´ í˜ì´ì§€ ìˆ˜
          metadata: {
            pages: wordData.pageCount,
            author: 'Unknown',
            lastModified: new Date().toISOString()
          }
        }

        console.log('[íŒŒì¼ íŒŒì‹±] Word parsedData ìƒì„± ì™„ë£Œ:', {
          fileType: parsedData.fileType,
          fileName: parsedData.fileName,
          extractedTextLength: parsedData.extractedText.length,
          pageTextsCount: parsedData.pageTexts.length
        })

        resolve(parsedData)
      } else if (file.type.includes('sheet') || file.type.includes('excel') || file.name.endsWith('.xlsx') || file.name.endsWith('.xls')) {
        // Excel íŒŒì¼ - ì‹¤ì œ ë‚´ìš© ì¶”ì¶œ
        console.log('[íŒŒì¼ íŒŒì‹±] Excel íŒŒì¼ ê°ì§€:', file.name)
        const excelData = await extractExcelText(file)

        console.log('[íŒŒì¼ íŒŒì‹±] Excel ì¶”ì¶œ ì™„ë£Œ - í…ìŠ¤íŠ¸ ê¸¸ì´:', excelData.text.length)

        parsedData = {
          fileType: 'excel',
          fileName: file.name,
          fileSize: file.size,
          content: excelData.text.substring(0, 500) + '...', // ë¯¸ë¦¬ë³´ê¸°ìš©
          extractedText: excelData.text, // ì‹¤ì œ ì „ì²´ ë‚´ìš©
          pageTexts: excelData.pageTexts, // ì‹œíŠ¸ë³„ í…ìŠ¤íŠ¸ (í˜ì´ì§€ë¡œ ì·¨ê¸‰)
          pageImages: excelData.pageImages,
          pageCount: excelData.pageCount, // ì „ì²´ ì‹œíŠ¸ ìˆ˜
          sheets: excelData.sheets, // ì‹œíŠ¸ë³„ ì›ë³¸ ë°ì´í„°
          sheetNames: excelData.sheetNames,
          metadata: {
            sheets: excelData.sheetNames,
            totalSheets: excelData.pageCount,
            totalRows: Object.values(excelData.sheets).reduce((sum, sheet) => sum + sheet.rowCount, 0),
            totalColumns: Math.max(...Object.values(excelData.sheets).map(sheet => sheet.columnCount), 0)
          }
        }

        console.log('[íŒŒì¼ íŒŒì‹±] Excel parsedData ìƒì„± ì™„ë£Œ:', {
          fileType: parsedData.fileType,
          fileName: parsedData.fileName,
          extractedTextLength: parsedData.extractedText.length,
          sheetsCount: parsedData.sheetNames.length
        })

        resolve(parsedData)
      } else {
        // ê¸°íƒ€ íŒŒì¼ - ì§€ì›í•˜ì§€ ì•ŠìŒ
        parsedData = {
          fileType: 'unknown',
          fileName: file.name,
          fileSize: file.size,
          content: 'ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤.',
          extractedText: `ì´ íŒŒì¼(${file.name})ì€ í˜„ì¬ ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹ì…ë‹ˆë‹¤.\n\nì§€ì› í˜•ì‹: PDF, TXT, JSON\n\nWordë‚˜ Excel íŒŒì¼ì€ PDF ë˜ëŠ” TXTë¡œ ë³€í™˜í•˜ì—¬ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.`
        }
        resolve(parsedData)
      }
    } catch (error) {
      console.error('íŒŒì¼ íŒŒì‹± ì˜¤ë¥˜:', error)
      reject(error)
    }
  })
}

// íŒŒì¼ í¬ê¸° í¬ë§·íŒ…
export const formatFileSize = (bytes) => {
  if (bytes === 0) return '0 Bytes'
  const k = 1024
  const sizes = ['Bytes', 'KB', 'MB', 'GB']
  const i = Math.floor(Math.log(bytes) / Math.log(k))
  return Math.round(bytes / Math.pow(k, i) * 100) / 100 + ' ' + sizes[i]
}

// ì›¹ URLì—ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
export const fetchWebMetadata = async (url) => {
  try {
    // URL ìœ íš¨ì„± ê²€ì‚¬
    const urlObj = new URL(url)

    // CORS í”„ë¡ì‹œë¥¼ ì‚¬ìš©í•˜ê±°ë‚˜ ë°±ì—”ë“œ APIë¥¼ í†µí•´ ë©”íƒ€ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì•¼ í•¨
    // í˜„ì¬ëŠ” ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ë¥¼ ë°˜í™˜

    // ì‹¤ì œ êµ¬í˜„ ì‹œ: fetchë¥¼ í†µí•´ HTMLì„ ê°€ì ¸ì˜¨ í›„ ë©”íƒ€ íƒœê·¸ íŒŒì‹±
    // const response = await fetch(url)
    // const html = await response.text()
    // const parser = new DOMParser()
    // const doc = parser.parseFromString(html, 'text/html')

    // ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° ìƒì„±
    const metadata = {
      fileType: 'web',
      url: url,
      domain: urlObj.hostname,
      protocol: urlObj.protocol,
      fetchedAt: new Date().toISOString(),
      metadata: {
        title: `${urlObj.hostname}ì˜ ì›¹í˜ì´ì§€`,
        description: 'ì´ ì›¹í˜ì´ì§€ëŠ” ë‹¤ì–‘í•œ ì •ë³´ë¥¼ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë©”íƒ€ íƒœê·¸ì—ì„œ ì¶”ì¶œë©ë‹ˆë‹¤.',
        author: 'Unknown',
        keywords: ['AI', 'ê¸°ìˆ ', 'ë¬¸ì„œ', 'ë¶„ì„'],
        language: 'ko',
        publishedDate: new Date().toISOString()
      },
      content: {
        headings: [
          'AI ê¸°ë°˜ ë¬¸ì„œ ë¶„ì„ ì‹œìŠ¤í…œ',
          'ì£¼ìš” ê¸°ëŠ¥',
          'ê¸°ìˆ  ìŠ¤íƒ',
          'ì‚¬ìš© ë°©ë²•'
        ],
        paragraphs: [
          'ë³¸ ì‹œìŠ¤í…œì€ ì²¨ë‹¨ AI ê¸°ìˆ ì„ í™œìš©í•˜ì—¬ ë¬¸ì„œë¥¼ ìë™ìœ¼ë¡œ ë¶„ì„í•˜ê³  ì´í•´í•©ë‹ˆë‹¤.',
          'ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ ë¬¸ì„œë‚˜ ì›¹ í˜ì´ì§€ì˜ ë‚´ìš©ì„ íŒŒì‹±í•˜ì—¬ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.',
          'ìì—°ì–´ ì²˜ë¦¬ ê¸°ìˆ ì„ í†µí•´ ë¬¸ì„œì˜ í•µì‹¬ ë‚´ìš©ì„ ì¶”ì¶œí•˜ê³  ì§ˆì˜ì‘ë‹µì„ ì§€ì›í•©ë‹ˆë‹¤.',
          'ë‹¤ì–‘í•œ íŒŒì¼ í˜•ì‹(PDF, Word, Excel, TXT, JSON)ì„ ì§€ì›í•˜ë©°, ì›¹ URLë¡œë¶€í„° ì§ì ‘ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.'
        ],
        links: [
          { text: 'GitHub', url: 'https://github.com' },
          { text: 'Documentation', url: `${url}/docs` },
          { text: 'API Reference', url: `${url}/api` }
        ]
      },
      extractedText: `ì›¹í˜ì´ì§€ ì œëª©: ${urlObj.hostname}ì˜ ì›¹í˜ì´ì§€\n\nURL: ${url}\n\nì£¼ìš” ë‚´ìš©:\n\nAI ê¸°ë°˜ ë¬¸ì„œ ë¶„ì„ ì‹œìŠ¤í…œ\në³¸ ì‹œìŠ¤í…œì€ ì²¨ë‹¨ AI ê¸°ìˆ ì„ í™œìš©í•˜ì—¬ ë¬¸ì„œë¥¼ ìë™ìœ¼ë¡œ ë¶„ì„í•˜ê³  ì´í•´í•©ë‹ˆë‹¤.\n\nì£¼ìš” ê¸°ëŠ¥\nì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ ë¬¸ì„œë‚˜ ì›¹ í˜ì´ì§€ì˜ ë‚´ìš©ì„ íŒŒì‹±í•˜ì—¬ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\nìì—°ì–´ ì²˜ë¦¬ ê¸°ìˆ ì„ í†µí•´ ë¬¸ì„œì˜ í•µì‹¬ ë‚´ìš©ì„ ì¶”ì¶œí•˜ê³  ì§ˆì˜ì‘ë‹µì„ ì§€ì›í•©ë‹ˆë‹¤.\n\nê¸°ìˆ  ìŠ¤íƒ\n- React 18\n- Vite\n- Tailwind CSS\n- ìì—°ì–´ ì²˜ë¦¬ AI\n\nì‚¬ìš© ë°©ë²•\n1. íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê±°ë‚˜ ì›¹ URLì„ ì…ë ¥í•©ë‹ˆë‹¤\n2. ì‹œìŠ¤í…œì´ ìë™ìœ¼ë¡œ ë‚´ìš©ì„ ë¶„ì„í•©ë‹ˆë‹¤\n3. ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ë¥¼ í†µí•´ ì§ˆë¬¸ì„ ì…ë ¥í•©ë‹ˆë‹¤\n4. AIê°€ ë¬¸ì„œ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤`,
      stats: {
        wordCount: 250,
        paragraphCount: 8,
        linkCount: 3,
        imageCount: 5
      }
    }

    return metadata
  } catch (error) {
    console.error('URL ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì˜¤ë¥˜:', error)
    throw new Error('ìœ íš¨í•˜ì§€ ì•Šì€ URLì…ë‹ˆë‹¤.')
  }
}

// JSON ë°ì´í„°ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (RAGìš©)
export const extractTextFromParsedData = (parsedData) => {
  console.log('[extractTextFromParsedData] ì‹œì‘ - parsedData:', {
    exists: !!parsedData,
    fileType: parsedData?.fileType,
    fileName: parsedData?.fileName,
    hasExtractedText: !!parsedData?.extractedText,
    extractedTextLength: parsedData?.extractedText?.length || 0
  })

  if (!parsedData) {
    console.log('[extractTextFromParsedData] parsedDataê°€ ì—†ìŒ')
    return ''
  }

  let text = ''

  // íŒŒì¼ ê¸°ë³¸ ì •ë³´
  if (parsedData.fileType === 'web') {
    // ì›¹ ì†ŒìŠ¤ì¸ ê²½ìš°
    text += `ì›¹í˜ì´ì§€ ì œëª©: ${parsedData.metadata?.title || parsedData.url}\n`
    text += `URL: ${parsedData.url}\n`
    text += `ë„ë©”ì¸: ${parsedData.domain}\n\n`

    if (parsedData.metadata?.description) {
      text += `ì„¤ëª…: ${parsedData.metadata.description}\n\n`
    }
  } else {
    // íŒŒì¼ ì†ŒìŠ¤ì¸ ê²½ìš°
    text += `íŒŒì¼ëª…: ${parsedData.fileName || parsedData.fileInfo?.name}\n`
    text += `íŒŒì¼ íƒ€ì…: ${parsedData.fileType}\n\n`
  }

  // ë‚´ìš© ì¶”ì¶œ
  if (parsedData.content) {
    if (typeof parsedData.content === 'string') {
      text += parsedData.content + '\n\n'
    } else if (typeof parsedData.content === 'object') {
      // ì›¹ ì½˜í…ì¸  ê°ì²´ì¸ ê²½ìš°
      if (parsedData.content.headings) {
        text += 'ì œëª©ë“¤:\n' + parsedData.content.headings.join('\n') + '\n\n'
      }
      if (parsedData.content.paragraphs) {
        text += 'ë³¸ë¬¸:\n' + parsedData.content.paragraphs.join('\n\n') + '\n\n'
      }
    }
  }

  if (parsedData.extractedText) {
    text += parsedData.extractedText + '\n\n'
  }

  // ì¤„ ë‹¨ìœ„ ë‚´ìš© (TXT)
  if (parsedData.lines && Array.isArray(parsedData.lines)) {
    text += parsedData.lines.join('\n') + '\n\n'
  }

  // Excel ë°ì´í„°
  if (parsedData.sheets) {
    Object.values(parsedData.sheets).forEach(sheet => {
      if (sheet.data && Array.isArray(sheet.data)) {
        text += `[${sheet.name}]\n`
        sheet.data.forEach(row => {
          text += JSON.stringify(row) + '\n'
        })
        text += '\n'
      }
    })
  }

  // ë©”íƒ€ë°ì´í„°
  if (parsedData.metadata) {
    text += `ë©”íƒ€ë°ì´í„°: ${JSON.stringify(parsedData.metadata, null, 2)}\n`
  }

  console.log('[extractTextFromParsedData] ì™„ë£Œ - ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ê¸¸ì´:', text.length)
  console.log('[extractTextFromParsedData] ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ì²« 300ì:', text.substring(0, 300))

  return text
}
