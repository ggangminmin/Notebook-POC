import * as pdfjsLib from 'pdfjs-dist'
import mammoth from 'mammoth'
import * as XLSX from 'xlsx'
import JSZip from 'jszip'
import { parse as parseHWP } from '@hwp.js/parser'

// PDF.js worker ì„¤ì • - ë¡œì»¬ ì›Œì»¤ ì‚¬ìš©
pdfjsLib.GlobalWorkerOptions.workerSrc = new URL(
  'pdfjs-dist/build/pdf.worker.min.mjs',
  import.meta.url
).toString()

// ğŸ“„ í…ìŠ¤íŠ¸ ê°€ìƒ í˜ì´ì§€ ë¶„í•  (ì•½ 2000ì ë‹¨ìœ„)
export const virtualizeText = (text, pageSize = 2000) => {
  if (!text) return { pageCount: 1, pageTexts: [] }

  const trimmedText = text.trim()
  const pageTexts = []

  for (let i = 0; i < trimmedText.length; i += pageSize) {
    const pageNum = Math.floor(i / pageSize) + 1
    const content = trimmedText.substring(i, i + pageSize)
    pageTexts.push({
      pageNumber: pageNum,
      text: content,
      wordCount: content.split(/\s+/).length,
      thumbnail: null
    })
  }

  return {
    pageCount: pageTexts.length || 1,
    pageTexts: pageTexts
  }
}

// PDF í˜ì´ì§€ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜ (ì¸ë„¤ì¼ìš© - íšŒì „ ì •ë³´ ì •ê·œí™” + ê³ í•´ìƒë„)
const renderPDFPageToImage = async (page, scale = 0.6) => {
  try {
    // PDF í˜ì´ì§€ì˜ íšŒì „ ì •ë³´ë¥¼ ë¬´ì‹œí•˜ê³  í•­ìƒ 0ë„ë¡œ ê³ ì • (ì •ë°©í–¥)
    const viewport = page.getViewport({ scale, rotation: 0 })
    const canvas = document.createElement('canvas')
    const context = canvas.getContext('2d')

    // ê³ í•´ìƒë„ ë Œë”ë§ì„ ìœ„í•œ í”½ì…€ ë°€ë„ ì¡°ì • (3.0ë°°ë¡œ ë§¤ìš° ì„ ëª…í•˜ê²Œ)
    const outputScale = 3.0
    canvas.width = Math.floor(viewport.width * outputScale)
    canvas.height = Math.floor(viewport.height * outputScale)

    // ì»¨í…ìŠ¤íŠ¸ ì´ˆê¸°í™” ë° ë°°ê²½ í°ìƒ‰ìœ¼ë¡œ ì„¤ì •
    context.fillStyle = 'white'
    context.fillRect(0, 0, canvas.width, canvas.height)

    // Identity Matrixë¡œ ì¢Œí‘œê³„ ì™„ì „ ë¦¬ì…‹ (ë°˜ì „ ë°©ì§€ - ì „ì—­ ì ìš©)
    context.setTransform(outputScale, 0, 0, outputScale, 0, 0)

    await page.render({
      canvasContext: context,
      viewport: viewport
    }).promise

    // Canvasë¥¼ Base64 ì´ë¯¸ì§€ë¡œ ë³€í™˜ (ìµœê³  í’ˆì§ˆ)
    return canvas.toDataURL('image/png', 1.0)
  } catch (error) {
    console.error('[PDF ì´ë¯¸ì§€ ë³€í™˜] ì˜¤ë¥˜:', error)
    return null
  }
}

// Word íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (êµ¬ì¡° ë³´ì¡´í˜•)
const extractWordText = async (file) => {
  try {
    console.log('[Word ì¶”ì¶œ] ì‹œì‘:', file.name, 'Size:', file.size)
    const arrayBuffer = await file.arrayBuffer()

    // HTMLë¡œ ë³€í™˜í•˜ì—¬ êµ¬ì¡° ë³´ì¡´ (í‘œ, ëª©ë¡, ì œëª© ë“±)
    const result = await mammoth.convertToHtml({ arrayBuffer })
    const html = result.value

    // ë‹¨ìˆœ í…ìŠ¤íŠ¸ë„ ì¶”ì¶œ (RAGìš©)
    const textResult = await mammoth.extractRawText({ arrayBuffer })
    const rawText = textResult.value

    // HTMLì„ ë‹¨ë½ ë‹¨ìœ„ë¡œ íŒŒì‹±í•˜ì—¬ ìì—°ìŠ¤ëŸ¬ìš´ í˜ì´ì§€ ë¶„í•  ì‹œë„
    // ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•˜ê²Œ <p>, <h1-6>, <table> íƒœê·¸ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë‚˜ëˆ”
    const parser = new DOMParser()
    const doc = parser.parseFromString(html, 'text/html')
    const elements = Array.from(doc.body.children)

    const pageTexts = []
    let currentPageContent = ''
    let currentPageWords = 0
    let pageNumber = 1
    const wordsPerPage = 600 // ìì—°ìŠ¤ëŸ¬ìš´ ë‹¨ë½ ëŠê¸°ë¥¼ ê³ ë ¤í•˜ì—¬ ì•½ê°„ ìƒí–¥ ì¡°ì •

    elements.forEach((el, index) => {
      const elText = el.textContent || ''
      const elWords = elText.split(/\s+/).filter(Boolean).length

      // í˜„ì¬ ìš”ì†Œì˜ HTML ì¶”ê°€
      currentPageContent += el.outerHTML
      currentPageWords += elWords

      // í˜ì´ì§€ êµ¬ë¶„ ê¸°ì¤€: ë‹¨ì–´ ìˆ˜ê°€ ë„˜ì—ˆê±°ë‚˜, ë‹¤ìŒ ìš”ì†Œê°€ ì œëª©(h1, h2)ì´ê±°ë‚˜, ë§ˆì§€ë§‰ ìš”ì†Œì¸ ê²½ìš°
      const nextEl = elements[index + 1]
      const isNextHeading = nextEl && ['H1', 'H2', 'H3'].includes(nextEl.tagName)

      if (currentPageWords >= wordsPerPage || isNextHeading || index === elements.length - 1) {
        if (currentPageContent.trim()) {
          pageTexts.push({
            pageNumber: pageNumber++,
            text: currentPageContent, // HTML ë‚´ìš© ì €ì¥
            isHtml: true, // HTMLì„ì„ í‘œì‹œ
            wordCount: currentPageWords,
            thumbnail: null
          })
          currentPageContent = ''
          currentPageWords = 0
        }
      }
    })

    console.log('[Word ì¶”ì¶œ] ì™„ë£Œ - í˜ì´ì§€:', pageTexts.length)

    return {
      text: rawText,
      pageCount: pageTexts.length,
      pageTexts: pageTexts,
      pageImages: []
    }
  } catch (error) {
    console.error('[Word ì¶”ì¶œ] ì˜¤ë¥˜:', error)
    throw new Error('Word íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
  }
}

// Excel íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
const extractExcelText = async (file) => {
  try {
    console.log('[Excel ì¶”ì¶œ] ì‹œì‘:', file.name, 'Size:', file.size)
    const arrayBuffer = await file.arrayBuffer()
    const workbook = XLSX.read(arrayBuffer, { type: 'array' })

    let fullText = ''
    const sheets = {}
    const pageTexts = []
    let pageNumber = 1

    workbook.SheetNames.forEach((sheetName) => {
      const worksheet = workbook.Sheets[sheetName]
      const jsonData = XLSX.utils.sheet_to_json(worksheet, { header: 1, defval: '' })

      // ì‹œíŠ¸ ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
      let sheetText = `[ì‹œíŠ¸: ${sheetName}]\n\n`

      jsonData.forEach((row, rowIndex) => {
        if (row.some(cell => cell !== '')) { // ë¹ˆ í–‰ ì œì™¸
          const rowText = row.map((cell, colIndex) => {
            return cell !== '' ? `${cell}` : ''
          }).filter(cell => cell !== '').join(' | ')

          if (rowText) {
            sheetText += rowText + '\n'
          }
        }
      })

      fullText += sheetText + '\n\n'

      // ì‹œíŠ¸ë³„ í˜ì´ì§€ ìƒì„± (ê° ì‹œíŠ¸ë¥¼ ë³„ë„ í˜ì´ì§€ë¡œ)
      pageTexts.push({
        pageNumber: pageNumber++,
        text: sheetText,
        wordCount: sheetText.split(/\s+/).length,
        thumbnail: null,
        sheetName: sheetName
      })

      sheets[sheetName] = {
        name: sheetName,
        data: jsonData,
        rowCount: jsonData.length,
        columnCount: jsonData[0]?.length || 0
      }
    })

    console.log('[Excel ì¶”ì¶œ] ì™„ë£Œ - ì´ ì‹œíŠ¸:', workbook.SheetNames.length)

    return {
      text: fullText,
      pageCount: workbook.SheetNames.length,
      pageTexts: pageTexts,
      pageImages: [],
      sheets: sheets,
      sheetNames: workbook.SheetNames
    }
  } catch (error) {
    console.error('[Excel ì¶”ì¶œ] ì˜¤ë¥˜:', error)
    throw new Error('Excel íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
  }
}

// PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (í˜ì´ì§€ë³„ ë©”íƒ€ë°ì´í„° + ì´ë¯¸ì§€ í¬í•¨)
const extractPDFText = async (file) => {
  try {
    console.log('[PDF ì¶”ì¶œ] ì‹œì‘:', file.name, 'Size:', file.size)
    const arrayBuffer = await file.arrayBuffer()
    const pdf = await pdfjsLib.getDocument({ data: arrayBuffer }).promise
    let fullText = ''
    const pageTexts = [] // í˜ì´ì§€ë³„ í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€ ì €ì¥
    const pageImages = [] // í˜ì´ì§€ë³„ ì¸ë„¤ì¼ ì´ë¯¸ì§€

    console.log('[PDF ì¶”ì¶œ] PDF ë¡œë“œ ì„±ê³µ, ì´ í˜ì´ì§€:', pdf.numPages)

    for (let i = 1; i <= pdf.numPages; i++) {
      const page = await pdf.getPage(i)
      const textContent = await page.getTextContent()

      // ë””ë²„ê¹…: ì²« ë²ˆì§¸ í˜ì´ì§€ì˜ ì²« 5ê°œ ì•„ì´í…œ ì¶œë ¥
      if (i === 1) {
        console.log('[PDF ì¶”ì¶œ] ì²« í˜ì´ì§€ í…ìŠ¤íŠ¸ ì•„ì´í…œ ìƒ˜í”Œ:',
          textContent.items.slice(0, 5).map(item => ({
            str: item.str,
            length: item.str.length,
            charCodes: Array.from(item.str).map(c => c.charCodeAt(0))
          }))
        )
      }

      // ê° í…ìŠ¤íŠ¸ ì•„ì´í…œì„ ê³µë°±ìœ¼ë¡œ ì—°ê²°
      const pageText = textContent.items
        .map(item => item.str)
        .filter(str => str.trim().length > 0) // ë¹ˆ ë¬¸ìì—´ ì œê±°
        .join(' ')

      // ğŸ”¥ ì„ì‹œ: IndexedDB ì €ì¥ì„ ìœ„í•´ ì¸ë„¤ì¼ ë¹„í™œì„±í™” (Base64 ì´ë¯¸ì§€ê°€ ë„ˆë¬´ í¼)
      // const thumbnail = await renderPDFPageToImage(page, 0.6)
      const thumbnail = null // ì¸ë„¤ì¼ ë¹„í™œì„±í™”

      // í˜ì´ì§€ë³„ ë°ì´í„° ì €ì¥
      pageTexts.push({
        pageNumber: i,
        text: pageText,
        wordCount: pageText.split(/\s+/).length,
        thumbnail: thumbnail // nullë¡œ ì €ì¥
      })

      pageImages.push({
        pageNumber: i,
        thumbnail: thumbnail
      })

      fullText += pageText + '\n\n'

      if (i === 1) {
        console.log('[PDF ì¶”ì¶œ] ì²« í˜ì´ì§€ ì¶”ì¶œ ê²°ê³¼ (ì²« 200ì):', pageText.substring(0, 200))
        console.log('[PDF ì¶”ì¶œ] ì¸ë„¤ì¼ ìƒì„±:', thumbnail ? 'ì„±ê³µ' : 'ì‹¤íŒ¨')
      }
    }

    const finalText = fullText.trim()
    console.log('[PDF ì¶”ì¶œ] ì™„ë£Œ - ì´ ê¸¸ì´:', finalText.length, 'ì¸ë„¤ì¼ ê°œìˆ˜:', pageImages.length)

    return {
      text: finalText,
      pageCount: pdf.numPages,
      pageTexts: pageTexts, // í˜ì´ì§€ë³„ í…ìŠ¤íŠ¸ + ì¸ë„¤ì¼ ë°°ì—´
      pageImages: pageImages // í˜ì´ì§€ë³„ ì¸ë„¤ì¼ë§Œ ë³„ë„ ì €ì¥
    }
  } catch (error) {
    console.error('[PDF ì¶”ì¶œ] ì˜¤ë¥˜:', error)
    throw new Error('PDF íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
  }
}

// HWPX íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ZIP + XML)
const extractHWPXText = async (file) => {
  try {
    console.log('[HWPX ì¶”ì¶œ] ì‹œì‘:', file.name, 'Size:', file.size)
    const arrayBuffer = await file.arrayBuffer()
    const zip = await JSZip.loadAsync(arrayBuffer)

    // Contents í´ë” ë‚´ì˜ section*.xml íŒŒì¼ë“¤ì„ ìˆœíšŒí•˜ë©° í…ìŠ¤íŠ¸ ì¶”ì¶œ
    let fullText = ''
    const sectionFiles = Object.keys(zip.files).filter(name => name.startsWith('Contents/section') && name.endsWith('.xml'))

    // ì„¹ì…˜ ìˆœì„œëŒ€ë¡œ ì •ë ¬ (section0.xml, section1.xml ...)
    sectionFiles.sort((a, b) => {
      const numA = parseInt(a.match(/\d+/)[0])
      const numB = parseInt(b.match(/\d+/)[0])
      return numA - numB
    })

    console.log('[HWPX ì¶”ì¶œ] ë°œê²¬ëœ ì„¹ì…˜:', sectionFiles)

    for (const fileName of sectionFiles) {
      const xmlContent = await zip.files[fileName].async('text')
      const parser = new DOMParser()
      const xmlDoc = parser.parseFromString(xmlContent, 'text/xml')

      // <hp:t> íƒœê·¸ ë‚´ì˜ í…ìŠ¤íŠ¸ê°€ ì‹¤ì œ ë³¸ë¬¸ ë‚´ìš©ì„
      const textNodes = xmlDoc.getElementsByTagName('hp:t')
      let sectionText = ''
      for (let i = 0; i < textNodes.length; i++) {
        sectionText += textNodes[i].textContent + ' '
      }
      fullText += sectionText + '\n\n'
    }

    const { pageCount, pageTexts } = virtualizeText(fullText)

    return {
      text: fullText,
      pageCount,
      pageTexts,
      pageImages: []
    }
  } catch (error) {
    console.error('[HWPX ì¶”ì¶œ] ì˜¤ë¥˜:', error)
    throw new Error('HWPX íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
  }
}

// HWP íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (@hwp.js/parser ì‚¬ìš©)
const extractHWPText = async (file) => {
  try {
    console.log('[HWP ì¶”ì¶œ] ì‹œì‘:', file.name, 'Size:', file.size)
    const arrayBuffer = await file.arrayBuffer()

    // @hwp.js/parser ì‚¬ìš©
    const hwpDoc = parseHWP(arrayBuffer)
    let fullText = ''

    // ì„¹ì…˜ -> ë¬¸ë‹¨ -> ê¸€ì ìˆœìœ¼ë¡œ ìˆœíšŒí•˜ë©° í…ìŠ¤íŠ¸ ì¶”ì¶œ
    hwpDoc.sections.forEach(section => {
      section.paragraphs.forEach(paragraph => {
        // paragraph.charsëŠ” ë°˜ë³µ ê°€ëŠ¥í•œ ê°ì²´ (CharList)
        for (const char of paragraph.chars) {
          if (char && typeof char.toString === 'function') {
            const charStr = char.toString()
            if (charStr) {
              fullText += charStr
            }
          }
        }
        fullText += '\n'
      })
      fullText += '\n'
    })

    console.log('[HWP ì¶”ì¶œ] í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ, ê¸¸ì´:', fullText.length)

    const { pageCount, pageTexts } = virtualizeText(fullText)

    return {
      text: fullText,
      pageCount,
      pageTexts,
      pageImages: []
    }
  } catch (error) {
    console.error('[HWP ì¶”ì¶œ] ì˜¤ë¥˜:', error)
    throw new Error('HWP íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ì§€ì›ë˜ì§€ ì•ŠëŠ” ë²„ì „ì´ê±°ë‚˜ ì†ìƒëœ íŒŒì¼ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.)')
  }
}

// íŒŒì¼ ë‚´ìš©ì„ íŒŒì‹±í•˜ì—¬ êµ¬ì¡°í™”ëœ JSONìœ¼ë¡œ ë³€í™˜
export const parseFileContent = async (file) => {
  return new Promise(async (resolve, reject) => {
    try {
      let parsedData = {}

      if (file.type === 'application/json') {
        // JSON íŒŒì¼ì¸ ê²½ìš°
        const reader = new FileReader()
        reader.onload = (e) => {
          try {
            parsedData = JSON.parse(e.target.result)
            resolve(parsedData)
          } catch (error) {
            reject(new Error('JSON íŒŒì¼ íŒŒì‹± ì‹¤íŒ¨'))
          }
        }
        reader.onerror = () => reject(new Error('íŒŒì¼ ì½ê¸° ì‹¤íŒ¨'))
        reader.readAsText(file)
      } else if (file.type === 'text/plain' || file.name.endsWith('.txt')) {
        // TXT íŒŒì¼ì¸ ê²½ìš° - ì‹¤ì œ ë‚´ìš© ì½ê¸° + í˜ì´ì§€ êµ¬ì¡° ì¶”ê°€
        const reader = new FileReader()
        reader.onload = (e) => {
          const content = e.target.result
          const lines = content.split('\n').filter(line => line.trim())

          // TXT íŒŒì¼ì„ í˜ì´ì§€ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ê¸° (500ë‹¨ì–´ë‹¹ 1í˜ì´ì§€ë¡œ ê°€ì •)
          const wordsPerPage = 500
          const words = content.split(/\s+/)
          const totalPages = Math.max(1, Math.ceil(words.length / wordsPerPage))
          const pageTexts = []

          for (let i = 0; i < totalPages; i++) {
            const startIdx = i * wordsPerPage
            const endIdx = Math.min((i + 1) * wordsPerPage, words.length)
            const pageContent = words.slice(startIdx, endIdx).join(' ')

            pageTexts.push({
              pageNumber: i + 1,
              text: pageContent,
              wordCount: endIdx - startIdx,
              thumbnail: null // TXT íŒŒì¼ì€ ì¸ë„¤ì¼ ì—†ìŒ
            })
          }

          parsedData = {
            fileType: 'text',
            fileName: file.name,
            fileSize: file.size,
            encoding: 'utf-8',
            totalLines: lines.length,
            pageCount: totalPages,
            content: content,
            lines: lines,
            extractedText: content, // ì‹¤ì œ íŒŒì¼ ë‚´ìš©
            pageTexts: pageTexts, // í˜ì´ì§€ë³„ í…ìŠ¤íŠ¸ êµ¬ì¡° ì¶”ê°€
            metadata: {
              paragraphs: content.split('\n\n').filter(p => p.trim()).length,
              words: content.split(/\s+/).length,
              characters: content.length
            }
          }
          resolve(parsedData)
        }
        reader.onerror = () => reject(new Error('íŒŒì¼ ì½ê¸° ì‹¤íŒ¨'))
        reader.readAsText(file)
      } else if (file.type.includes('pdf') || file.name.endsWith('.pdf')) {
        // PDF íŒŒì¼ - ì‹¤ì œ ë‚´ìš© ì¶”ì¶œ
        console.log('[íŒŒì¼ íŒŒì‹±] PDF íŒŒì¼ ê°ì§€:', file.name)
        const pdfData = await extractPDFText(file)

        console.log('[íŒŒì¼ íŒŒì‹±] PDF ì¶”ì¶œ ì™„ë£Œ - í…ìŠ¤íŠ¸ ê¸¸ì´:', pdfData.text.length)
        console.log('[íŒŒì¼ íŒŒì‹±] extractedText ì²« 300ì:', pdfData.text.substring(0, 300))

        parsedData = {
          fileType: 'pdf',
          fileName: file.name,
          fileSize: file.size,
          content: pdfData.text.substring(0, 500) + '...', // ë¯¸ë¦¬ë³´ê¸°ìš©
          extractedText: pdfData.text, // ì‹¤ì œ ì „ì²´ ë‚´ìš©
          pageTexts: pdfData.pageTexts, // í˜ì´ì§€ë³„ í…ìŠ¤íŠ¸ + ì¸ë„¤ì¼ ë°°ì—´
          pageImages: pdfData.pageImages, // í˜ì´ì§€ë³„ ì¸ë„¤ì¼ë§Œ ë³„ë„ ì €ì¥
          pageCount: pdfData.pageCount, // ì „ì²´ í˜ì´ì§€ ìˆ˜
          metadata: {
            pages: pdfData.pageCount,
            author: 'Unknown',
            createdDate: new Date().toISOString()
          }
        }

        console.log('[íŒŒì¼ íŒŒì‹±] parsedData ìƒì„± ì™„ë£Œ:', {
          fileType: parsedData.fileType,
          fileName: parsedData.fileName,
          extractedTextLength: parsedData.extractedText.length,
          pageTextsCount: parsedData.pageTexts.length,
          pageImagesCount: parsedData.pageImages?.length || 0,
          extractedTextPreview: parsedData.extractedText.substring(0, 100)
        })

        resolve(parsedData)
      } else if (file.type.includes('word') || file.name.endsWith('.docx') || file.name.endsWith('.doc')) {
        // Word íŒŒì¼ - ì‹¤ì œ ë‚´ìš© ì¶”ì¶œ
        console.log('[íŒŒì¼ íŒŒì‹±] Word íŒŒì¼ ê°ì§€:', file.name)
        const wordData = await extractWordText(file)

        console.log('[íŒŒì¼ íŒŒì‹±] Word ì¶”ì¶œ ì™„ë£Œ - í…ìŠ¤íŠ¸ ê¸¸ì´:', wordData.text.length)

        parsedData = {
          fileType: 'word',
          fileName: file.name,
          fileSize: file.size,
          content: wordData.text.substring(0, 500) + '...', // ë¯¸ë¦¬ë³´ê¸°ìš©
          extractedText: wordData.text, // ì‹¤ì œ ì „ì²´ ë‚´ìš©
          pageTexts: wordData.pageTexts, // í˜ì´ì§€ë³„ í…ìŠ¤íŠ¸
          pageImages: wordData.pageImages,
          pageCount: wordData.pageCount, // ì „ì²´ í˜ì´ì§€ ìˆ˜
          metadata: {
            pages: wordData.pageCount,
            author: 'Unknown',
            lastModified: new Date().toISOString()
          }
        }

        console.log('[íŒŒì¼ íŒŒì‹±] Word parsedData ìƒì„± ì™„ë£Œ:', {
          fileType: parsedData.fileType,
          fileName: parsedData.fileName,
          extractedTextLength: parsedData.extractedText.length,
          pageTextsCount: parsedData.pageTexts.length
        })

        resolve(parsedData)
      } else if (file.name.endsWith('.hwpx')) {
        // HWPX íŒŒì¼ (í•œê¸€ ì‹ ë²„ì „)
        console.log('[íŒŒì¼ íŒŒì‹±] HWPX íŒŒì¼ ê°ì§€:', file.name)
        const hwpxData = await extractHWPXText(file)

        parsedData = {
          fileType: 'hwp',
          fileName: file.name,
          fileSize: file.size,
          content: hwpxData.text.substring(0, 500) + '...',
          extractedText: hwpxData.text,
          pageCount: hwpxData.pageCount,
          pageTexts: hwpxData.pageTexts,
          metadata: {
            format: 'HWPX',
            pages: hwpxData.pageCount
          }
        }
        resolve(parsedData)
      } else if (file.name.endsWith('.hwp')) {
        // HWP íŒŒì¼ (í•œê¸€ êµ¬ë²„ì „)
        console.log('[íŒŒì¼ íŒŒì‹±] HWP íŒŒì¼ ê°ì§€:', file.name)
        const hwpData = await extractHWPText(file)

        parsedData = {
          fileType: 'hwp',
          fileName: file.name,
          fileSize: file.size,
          content: hwpData.text.substring(0, 500) + '...',
          extractedText: hwpData.text,
          pageCount: hwpData.pageCount,
          pageTexts: hwpData.pageTexts,
          metadata: {
            format: 'HWP',
            pages: hwpData.pageCount
          }
        }
        resolve(parsedData)
      } else if (file.type.includes('sheet') || file.type.includes('excel') || file.name.endsWith('.xlsx') || file.name.endsWith('.xls')) {
        // Excel íŒŒì¼ - ì‹¤ì œ ë‚´ìš© ì¶”ì¶œ
        console.log('[íŒŒì¼ íŒŒì‹±] Excel íŒŒì¼ ê°ì§€:', file.name)
        const excelData = await extractExcelText(file)

        console.log('[íŒŒì¼ íŒŒì‹±] Excel ì¶”ì¶œ ì™„ë£Œ - í…ìŠ¤íŠ¸ ê¸¸ì´:', excelData.text.length)

        parsedData = {
          fileType: 'excel',
          fileName: file.name,
          fileSize: file.size,
          content: excelData.text.substring(0, 500) + '...', // ë¯¸ë¦¬ë³´ê¸°ìš©
          extractedText: excelData.text, // ì‹¤ì œ ì „ì²´ ë‚´ìš©
          pageTexts: excelData.pageTexts, // ì‹œíŠ¸ë³„ í…ìŠ¤íŠ¸ (í˜ì´ì§€ë¡œ ì·¨ê¸‰)
          pageImages: excelData.pageImages,
          pageCount: excelData.pageCount, // ì „ì²´ ì‹œíŠ¸ ìˆ˜
          sheets: excelData.sheets, // ì‹œíŠ¸ë³„ ì›ë³¸ ë°ì´í„°
          sheetNames: excelData.sheetNames,
          metadata: {
            sheets: excelData.sheetNames,
            totalSheets: excelData.pageCount,
            totalRows: Object.values(excelData.sheets).reduce((sum, sheet) => sum + sheet.rowCount, 0),
            totalColumns: Math.max(...Object.values(excelData.sheets).map(sheet => sheet.columnCount), 0)
          }
        }

        console.log('[íŒŒì¼ íŒŒì‹±] Excel parsedData ìƒì„± ì™„ë£Œ:', {
          fileType: parsedData.fileType,
          fileName: parsedData.fileName,
          extractedTextLength: parsedData.extractedText.length,
          sheetsCount: parsedData.sheetNames.length
        })

        resolve(parsedData)
      } else {
        // ê¸°íƒ€ íŒŒì¼ - ì§€ì›í•˜ì§€ ì•ŠìŒ
        parsedData = {
          fileType: 'unknown',
          fileName: file.name,
          fileSize: file.size,
          content: 'ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤.',
          extractedText: `ì´ íŒŒì¼(${file.name})ì€ í˜„ì¬ ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹ì…ë‹ˆë‹¤.\n\nì§€ì› í˜•ì‹: PDF, TXT, JSON\n\nWordë‚˜ Excel íŒŒì¼ì€ PDF ë˜ëŠ” TXTë¡œ ë³€í™˜í•˜ì—¬ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.`
        }
        resolve(parsedData)
      }
    } catch (error) {
      console.error('íŒŒì¼ íŒŒì‹± ì˜¤ë¥˜:', error)
      reject(error)
    }
  })
}

// íŒŒì¼ í¬ê¸° í¬ë§·íŒ…
export const formatFileSize = (bytes) => {
  if (bytes === 0) return '0 Bytes'
  const k = 1024
  const sizes = ['Bytes', 'KB', 'MB', 'GB']
  const i = Math.floor(Math.log(bytes) / Math.log(k))
  return Math.round(bytes / Math.pow(k, i) * 100) / 100 + ' ' + sizes[i]
}

// ìœ íŠœë¸Œ ìë§‰ ì¶”ì¶œ ì „ìš© í•¨ìˆ˜
const getYoutubeTranscript = async (videoId) => {
  try {
    console.log(`[Youtube] ìë§‰ ì¶”ì¶œ ì‹œë„: ${videoId}`)

    // 1. ìœ íŠœë¸Œ ë¹„ë””ì˜¤ í˜ì´ì§€ì—ì„œ ìë§‰ ì„¤ì • ì •ë³´ ì¶”ì¶œ ì‹œë„
    const videoUrl = `https://www.youtube.com/watch?v=${videoId}`
    const proxyUrl = `https://api.allorigins.win/get?url=${encodeURIComponent(videoUrl)}`

    const response = await fetch(proxyUrl)
    if (!response.ok) return null

    const data = await response.json()
    const html = data.contents

    // ytInitialPlayerResponse ê°ì²´ ì°¾ê¸°
    const regex = /ytInitialPlayerResponse\s*=\s*({.+?});/
    const match = html.match(regex)
    if (!match) return null

    const playerResponse = JSON.parse(match[1])
    const captionTracks = playerResponse?.captions?.playerCaptionsTracklistRenderer?.captionTracks

    if (!captionTracks || captionTracks.length === 0) {
      console.warn('[Youtube] ìë§‰ íŠ¸ë™ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
      return null
    }

    // í•œêµ­ì–´ ìë§‰ ìš°ì„ , ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ìë§‰ ì„ íƒ
    const track = captionTracks.find(t => t.languageCode === 'ko') ||
      captionTracks.find(t => t.languageCode === 'en') ||
      captionTracks[0]

    console.log(`[Youtube] ì‚¬ìš©ë  ìë§‰ ì–¸ì–´: ${track.languageCode}`)

    // 2. ì‹¤ì œ ìë§‰ í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° (XML/JSON3 í˜•ì‹)
    const transcriptProxyUrl = `https://api.allorigins.win/get?url=${encodeURIComponent(track.baseUrl + '&fmt=json3')}`
    const transcriptRes = await fetch(transcriptProxyUrl)
    if (!transcriptRes.ok) return null

    const transcriptData = await transcriptRes.json()
    const transcriptJson = JSON.parse(transcriptData.contents)

    // í…ìŠ¤íŠ¸ ì¡°ê°ë“¤ì„ í•©ì³ í•˜ë‚˜ì˜ ë³¸ë¬¸ìœ¼ë¡œ ìƒì„±
    const transcriptText = transcriptJson.events
      .filter(event => event.segs)
      .map(event => event.segs.map(s => s.utf8).join(''))
      .join(' ')
      .replace(/\s+/g, ' ')
      .trim()

    return transcriptText
  } catch (error) {
    console.error('[Youtube] ìë§‰ ì¶”ì¶œ ì¤‘ ìƒì„¸ ì˜¤ë¥˜:', error)
    return null
  }
}

// ì›¹ URLì—ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ (ì‹¤ì œ í¬ë¡¤ë§ ì‹œë„)
export const fetchWebMetadata = async (url) => {
  try {
    const urlObj = new URL(url)
    const isYouTube = urlObj.hostname.includes('youtube.com') || urlObj.hostname.includes('youtu.be')
    let videoId = null

    if (isYouTube) {
      if (urlObj.hostname.includes('youtube.com')) {
        videoId = urlObj.searchParams.get('v')
      } else if (urlObj.hostname.includes('youtu.be')) {
        videoId = urlObj.pathname.slice(1)
      }
    }

    console.log(`[fileParser] ì›¹ URL í¬ë¡¤ë§ ì‹œì‘ (${isYouTube ? 'YouTube' : 'Web'}): ${url}`)

    let extractedText = ""
    let title = `${urlObj.hostname}ì˜ ì›¹í˜ì´ì§€`

    // 1. YouTube ì „ìš© íŠ¹í™” ì²˜ë¦¬
    if (isYouTube && videoId) {
      // A. ì œëª© ê°€ì ¸ì˜¤ê¸° (oEmbed)
      try {
        const oembedUrl = `https://noembed.com/embed?url=${encodeURIComponent(url)}`
        const response = await fetch(oembedUrl)
        if (response.ok) {
          const data = await response.json()
          if (data.title) title = data.title
        }
      } catch (e) {
        console.warn('[fileParser] YouTube oEmbed ì‹¤íŒ¨')
      }

      // B. ìë§‰ ì¶”ì¶œ ì‹œë„ (ê°•ë ¥í•œ ì‹ ê·œ ì—”ì§„)
      const transcript = await getYoutubeTranscript(videoId)
      if (transcript && transcript.length > 50) {
        extractedText = `# ì˜ìƒ ì œëª©: ${title}\n\n## ìœ íŠœë¸Œ ìë§‰ ë‚´ìš©\n\n${transcript}`
        console.log('[fileParser] ìœ íŠœë¸Œ ìë§‰ ì¶”ì¶œ ì„±ê³µ!')
      }
    }

    // 2. ì¼ë°˜ ì›¹ í¬ë¡¤ë§ ë˜ëŠ” ìœ íŠœë¸Œ ìë§‰ ì‹¤íŒ¨ ì‹œ ëŒ€ì²´ ì‹œë„ (Jina Reader)
    if (!extractedText) {
      const jinaUrl = `https://r.jina.ai/${url}`
      try {
        const proxyUrl = `https://api.allorigins.win/get?url=${encodeURIComponent(jinaUrl)}`
        const response = await fetch(proxyUrl)
        if (response.ok) {
          const data = await response.json()
          const content = data.contents
          if (content && content.length > 200 && !content.includes('Captcha')) {
            extractedText = content
            if (title.includes(urlObj.hostname)) {
              const titleMatch = content.match(/^#\s+(.*)$/m)
              if (titleMatch) title = titleMatch[1].trim()
            }
          }
        }
      } catch (err) {
        console.error('[fileParser] ëŒ€ì²´ í¬ë¡¤ë§ ì‹¤íŒ¨:', err)
      }
    }

    // ìµœì¢… ê²°ê³¼ êµ¬ì„±
    if (!extractedText) {
      extractedText = isYouTube
        ? `ì˜ìƒ ì œëª©: ${title}\n\nURL: ${url}\n\nìœ íŠœë¸Œ ìë§‰ì„ ìë™ìœ¼ë¡œ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë³¸ë¬¸ ì•„ë˜ì˜ ì˜ìƒ í”Œë ˆì´ì–´ì—ì„œ ì§ì ‘ ì˜ìƒì„ ì‹œì²­í•˜ê±°ë‚˜ ë¸Œë¼ìš°ì €ì—ì„œ 'ìë§‰ ë³´ê¸°'ë¥¼ ì´ìš©í•´ì£¼ì„¸ìš”.`
        : `ì›¹í˜ì´ì§€ ì œëª©: ${title}\n\nURL: ${url}\n\në‚´ìš©ì„ ê°€ì ¸ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë¹„ê³µê°œ ì‚¬ì´íŠ¸ì´ê±°ë‚˜ í¬ë¡¤ë§ì´ ì°¨ë‹¨ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.`
    }

    const metadata = {
      fileType: 'web',
      url: url,
      domain: urlObj.hostname,
      protocol: urlObj.protocol,
      fetchedAt: new Date().toISOString(),
      metadata: {
        title: title,
        description: extractedText.substring(0, 300).replace(/\n/g, ' ') + '...',
        author: isYouTube ? 'YouTube Creator' : 'Unknown',
        language: 'ko',
        publishedDate: new Date().toISOString()
      },
      extractedText: extractedText
    }

    // ê°€ìƒ í˜ì´ì§€ ì¶”ê°€
    const virtualization = virtualizeText(metadata.extractedText)
    metadata.pageCount = virtualization.pageCount
    metadata.pageTexts = virtualization.pageTexts

    return metadata
  } catch (error) {
    console.error('URL ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì˜¤ë¥˜:', error)
    throw new Error('ìœ íš¨í•˜ì§€ ì•Šì€ URLì´ê±°ë‚˜ ìš”ì²­ì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤.')
  }
}

// JSON ë°ì´í„°ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (RAGìš©)
export const extractTextFromParsedData = (parsedData) => {
  console.log('[extractTextFromParsedData] ì‹œì‘ - parsedData:', {
    exists: !!parsedData,
    fileType: parsedData?.fileType,
    fileName: parsedData?.fileName,
    hasExtractedText: !!parsedData?.extractedText,
    extractedTextLength: parsedData?.extractedText?.length || 0
  })

  if (!parsedData) {
    console.log('[extractTextFromParsedData] parsedDataê°€ ì—†ìŒ')
    return ''
  }

  let text = ''

  // íŒŒì¼ ê¸°ë³¸ ì •ë³´
  if (parsedData.fileType === 'web') {
    // ì›¹ ì†ŒìŠ¤ì¸ ê²½ìš°
    text += `ì›¹í˜ì´ì§€ ì œëª©: ${parsedData.metadata?.title || parsedData.url}\n`
    text += `URL: ${parsedData.url}\n`
    text += `ë„ë©”ì¸: ${parsedData.domain}\n\n`

    if (parsedData.metadata?.description) {
      text += `ì„¤ëª…: ${parsedData.metadata.description}\n\n`
    }
  } else {
    // íŒŒì¼ ì†ŒìŠ¤ì¸ ê²½ìš°
    text += `íŒŒì¼ëª…: ${parsedData.fileName || parsedData.fileInfo?.name}\n`
    text += `íŒŒì¼ íƒ€ì…: ${parsedData.fileType}\n\n`
  }

  // ë‚´ìš© ì¶”ì¶œ
  if (parsedData.content) {
    if (typeof parsedData.content === 'string') {
      text += parsedData.content + '\n\n'
    } else if (typeof parsedData.content === 'object') {
      // ì›¹ ì½˜í…ì¸  ê°ì²´ì¸ ê²½ìš°
      if (parsedData.content.headings) {
        text += 'ì œëª©ë“¤:\n' + parsedData.content.headings.join('\n') + '\n\n'
      }
      if (parsedData.content.paragraphs) {
        text += 'ë³¸ë¬¸:\n' + parsedData.content.paragraphs.join('\n\n') + '\n\n'
      }
    }
  }

  if (parsedData.extractedText) {
    text += parsedData.extractedText + '\n\n'
  }

  // ì¤„ ë‹¨ìœ„ ë‚´ìš© (TXT)
  if (parsedData.lines && Array.isArray(parsedData.lines)) {
    text += parsedData.lines.join('\n') + '\n\n'
  }

  // Excel ë°ì´í„°
  if (parsedData.sheets) {
    Object.values(parsedData.sheets).forEach(sheet => {
      if (sheet.data && Array.isArray(sheet.data)) {
        text += `[${sheet.name}]\n`
        sheet.data.forEach(row => {
          text += JSON.stringify(row) + '\n'
        })
        text += '\n'
      }
    })
  }

  // ë©”íƒ€ë°ì´í„°
  if (parsedData.metadata) {
    text += `ë©”íƒ€ë°ì´í„°: ${JSON.stringify(parsedData.metadata, null, 2)}\n`
  }

  console.log('[extractTextFromParsedData] ì™„ë£Œ - ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ê¸¸ì´:', text.length)
  console.log('[extractTextFromParsedData] ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ì²« 300ì:', text.substring(0, 300))

  return text
}
